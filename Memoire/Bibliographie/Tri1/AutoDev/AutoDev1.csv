"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"J2TE8VHG","preprint","2024","Ramachandran, Gautham; Yang, Rick","CortexCompile: Harnessing Cortical-Inspired Architectures for Enhanced Multi-Agent NLP Code Synthesis","","","","10.48550/arXiv.2409.02938","http://arxiv.org/abs/2409.02938","Current approaches to automated code generation often rely on monolithic models that lack real-time adaptability and scalability. This limitation is particularly evident in complex programming tasks that require dynamic adjustment and efficiency. The integration of neuroscience principles into Natural Language Processing (NLP) has the potential to revolutionize automated code generation. This paper presents CortexCompile, a novel modular system inspired by the specialized functions of the human brain's cortical regions. By emulating the distinct roles of the Prefrontal Cortex, Parietal Cortex, Temporal Lobe, and Motor Cortex, CortexCompile achieves significant advancements in scalability, efficiency, and adaptability compared to traditional monolithic models like GPT-4o. The system's architecture features a Task Orchestration Agent that manages dynamic task delegation and parallel processing, facilitating the generation of highly accurate and optimized code across increasingly complex programming tasks. Experimental evaluations demonstrate that CortexCompile consistently outperforms GPT-4o in development time, accuracy, and user satisfaction, particularly in tasks involving real-time strategy games and first-person shooters. These findings underscore the viability of neuroscience-inspired architectures in addressing the limitations of current NLP models, paving the way for more efficient and human-like AI systems.","2024-08-23","2025-05-22 20:00:52","2025-05-22 20:00:52","2025-05-22 20:00:10","","","","","","","CortexCompile","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2409.02938 [cs]","","/Users/ksoares/Zotero/storage/FAK94JFB/Ramachandran et Yang - 2024 - CortexCompile Harnessing Cortical-Inspired Architectures for Enhanced Multi-Agent NLP Code Synthesi.pdf; /Users/ksoares/Zotero/storage/VTQ7P294/2409.html","","","Computer Science - Artificial Intelligence; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2409.02938","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V4SHJRW2","preprint","2024","Ishibashi, Yoichi; Nishimura, Yoshimasa","Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization","","","","10.48550/arXiv.2404.02183","http://arxiv.org/abs/2404.02183","Recent advancements in automatic code generation using large language model (LLM) agent have brought us closer to the future of automated software development. However, existing single-agent approaches face limitations in generating and improving large-scale, complex codebases due to constraints in context length. To tackle this challenge, we propose Self-Organized multi-Agent framework (SoA), a novel multi-agent framework that enables the scalable and efficient generation and optimization of large-scale code. In SoA, self-organized agents operate independently to generate and modify code components while seamlessly collaborating to construct the overall codebase. A key feature of our framework is the automatic multiplication of agents based on problem complexity, allowing for dynamic scalability. This enables the overall code volume to be increased indefinitely according to the number of agents, while the amount of code managed by each agent remains constant. We evaluate SoA on the HumanEval benchmark and demonstrate that, compared to a single-agent system, each agent in SoA handles significantly less code, yet the overall generated code is substantially greater. Moreover, SoA surpasses the powerful single-agent baseline by 5% in terms of Pass@1 accuracy.","2024-04-02","2025-05-22 20:00:52","2025-05-22 20:00:52","2025-05-22 20:00:16","","","","","","","Self-Organized Agents","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2404.02183 [cs]","","/Users/ksoares/Zotero/storage/6APRLSCY/Ishibashi et Nishimura - 2024 - Self-Organized Agents A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Opti.pdf; /Users/ksoares/Zotero/storage/HRR6Y5BL/2404.html","","","Computer Science - Computation and Language; Computer Science - Artificial Intelligence; Computer Science - Multiagent Systems; Computer Science - Software Engineering; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2404.02183","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PSCAZRST","conferencePaper","2024","Ramírez-Rueda, Rolando; Benítez-Guerrero, Edgard; Mezura-Godoy, Carmen; Bárcenas, Everardo","Transforming Software Development: A Study on the Integration of Multi-Agent Systems and Large Language Models for Automatic Code Generation","2024 12th International Conference in Software Engineering Research and Innovation (CONISOFT)","","","","https://ieeexplore.ieee.org/abstract/document/10795597/","This paper explores the integration of Multi-Agent Systems (MAS) and Large Language Models (LLMs) for auto-matic code generation, addressing the limitations of traditional manual coding. By conducting a comprehensive review of existing literature and analyzing a practical case study, we demonstrate how MAS and LLMs can collaboratively enhance software development processes. The research focuses on the technical and theoretical challenges of this integration, highlighting the potential for improved productivity, adaptability, and quality in code generation. The findings contribute to AI-based software engineering by revealing new research directions in collective intelligence and automated programming.","2024","2025-05-22 20:00:52","2025-05-26 13:27:48","2025-05-22 20:00:17","11–20","","","","","","Transforming Software Development","","","","","IEEE","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IS8HPPY4","journalArticle","2025","Ashraf, Bilal; Talavera, Gregory","Autonomous Agents in Software Engineering: A Multi-Agent LLM Approach","","","","","https://www.researchgate.net/profile/Gregory-Talavera/publication/388834987_Autonomous_Agents_in_Software_Engineering_A_Multi-Agent_LLM_Approach/links/67a90cc4461fb56424d320f9/Autonomous-Agents-in-Software-Engineering-A-Multi-Agent-LLM-Approach.pdf","The integration of autonomous agents in software engineering has the potential to revolutionize traditional development processes by automating complex tasks, enhancing collaboration, and optimizing productivity. Large Language Models (LLMs) have emerged as powerful tools for facilitating autonomous agent interactions, enabling software engineering workflows to be more intelligent and adaptive. This paper explores a multi-agent LLM approach, where autonomous agents perform various roles such as requirement analysis, code generation, testing, and debugging. By leveraging natural language processing capabilities, these agents can communicate, make decisions, and execute tasks with minimal human intervention. Experimental results demonstrate that multi-agent LLMs can streamline software development, reduce human errors, and accelerate project timelines. However, challenges related to model interpretability, coordination complexities, and error handling remain critical concerns. This study discusses the benefits, limitations, and future implications of integrating multi-agent LLMs in software engineering, emphasizing the need for further research to enhance agent reliability, contextual awareness, and ethical considerations. The findings suggest that a well-structured autonomous agent system can significantly improve software engineering efficiency while complementing human expertise in an agile development environment.","2025","2025-05-22 20:00:52","2025-05-26 13:21:05","2025-05-22 20:00:18","","","","","","","Autonomous Agents in Software Engineering","","","","","","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PF9FS7MF","preprint","2024","Islam, Md Ashraful; Ali, Mohammed Eunus; Parvez, Md Rizwan","MapCoder: Multi-Agent Code Generation for Competitive Problem Solving","","","","10.48550/arXiv.2405.11403","http://arxiv.org/abs/2405.11403","Code synthesis, which requires a deep understanding of complex natural language problem descriptions, generation of code instructions for complex algorithms and data structures, and the successful execution of comprehensive unit tests, presents a significant challenge. While large language models (LLMs) demonstrate impressive proficiency in natural language processing, their performance in code generation tasks remains limited. In this paper, we introduce a new approach to code generation tasks leveraging multi-agent prompting that uniquely replicates the full cycle of program synthesis as observed in human developers. Our framework, MapCoder, consists of four LLM agents specifically designed to emulate the stages of this cycle: recalling relevant examples, planning, code generation, and debugging. After conducting thorough experiments, with multiple LLM ablations and analyses across eight challenging competitive problem-solving and program synthesis benchmarks, MapCoder showcases remarkable code generation capabilities, achieving new state-of-the-art results (pass@1) on HumanEval (93.9%), MBPP (83.1%), APPS (22.0%), CodeContests (28.5%), and xCodeEval (45.3%). Moreover, our method consistently delivers superior performance across various programming languages and varying problem difficulties. We open-source our framework at https://github.com/Md-Ashraful-Pramanik/MapCoder.","2024-05-18","2025-05-22 20:00:52","2025-05-22 20:00:52","2025-05-22 20:00:20","","","","","","","MapCoder","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2405.11403 [cs]","","/Users/ksoares/Zotero/storage/6F3TNDGJ/Islam et al. - 2024 - MapCoder Multi-Agent Code Generation for Competitive Problem Solving.pdf; /Users/ksoares/Zotero/storage/5GMXRJ5T/2405.html","","","Computer Science - Computation and Language; Computer Science - Artificial Intelligence","","","","","","","","","","","","","","","","","","","arXiv:2405.11403","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZ44T2Q2","preprint","2024","Nunez, Ana; Islam, Nafis Tanveer; Jha, Sumit Kumar; Najafirad, Peyman","AutoSafeCoder: A Multi-Agent Framework for Securing LLM Code Generation through Static Analysis and Fuzz Testing","","","","10.48550/arXiv.2409.10737","http://arxiv.org/abs/2409.10737","Recent advancements in automatic code generation using large language models (LLMs) have brought us closer to fully automated secure software development. However, existing approaches often rely on a single agent for code generation, which struggles to produce secure, vulnerability-free code. Traditional program synthesis with LLMs has primarily focused on functional correctness, often neglecting critical dynamic security implications that happen during runtime. To address these challenges, we propose AutoSafeCoder, a multi-agent framework that leverages LLM-driven agents for code generation, vulnerability analysis, and security enhancement through continuous collaboration. The framework consists of three agents: a Coding Agent responsible for code generation, a Static Analyzer Agent identifying vulnerabilities, and a Fuzzing Agent performing dynamic testing using a mutation-based fuzzing approach to detect runtime errors. Our contribution focuses on ensuring the safety of multi-agent code generation by integrating dynamic and static testing in an iterative process during code generation by LLM that improves security. Experiments using the SecurityEval dataset demonstrate a 13% reduction in code vulnerabilities compared to baseline LLMs, with no compromise in functionality.","2024-11-05","2025-05-22 20:00:52","2025-05-22 20:00:52","2025-05-22 20:00:22","","","","","","","AutoSafeCoder","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2409.10737 [cs]","","/Users/ksoares/Zotero/storage/PJMBYIYI/Nunez et al. - 2024 - AutoSafeCoder A Multi-Agent Framework for Securing LLM Code Generation through Static Analysis and.pdf; /Users/ksoares/Zotero/storage/NJKTC4CJ/2409.html","","","Computer Science - Artificial Intelligence; Computer Science - Software Engineering","","","","","","","","","","","","","","","","","","","arXiv:2409.10737","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VNA6NDCG","conferencePaper","2024","Akram, Adjal; Abdennour, Sebbagh","Multi-agent system control based on first-order consensus algorithm","2024 International Conference on Advances in Electrical and Communication Technologies (ICAECOT)","","","","https://ieeexplore.ieee.org/abstract/document/10828920/","The goal of this study is to investigate the control of multi-agent systems (MAS) using consensus algorithms, which have gained important attention due to their applications in robotics. We explored the basics of graph theory to understand the network structure of MAS and categorized the different types of MAS with examples. This study focuses on consensus algorithms, testing their principles, types, and simulations. We used MATLAB to simulate and implement first-order consensus algorithms, validating our personal code against the results from the ODE45 solver (ordinary differential equation solver) and AI-generated (Artificial intelligence generated) code. The results demonstrate convergence and accuracy for all methods, confirming that our approach is feasible and reliable. This research presents a deeper understanding of MAS control and offers a robust strategy for future real-world practical applications.","2024","2025-05-22 20:00:52","2025-05-26 13:26:42","2025-05-22 20:00:22","1–6","","","","","","","","","","","IEEE","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LRV622MJ","journalArticle","2025","Wasif, Mubeen; Tunkel, David","Multi-Agent Collaboration in AI: Enhancing Software Development with Autonomous LLMs","","","","","https://www.researchgate.net/profile/David-Tunkel/publication/388834996_Multi-Agent_Collaboration_in_AI_Enhancing_Software_Development_with_Autonomous_LLMs/links/67a9104396e7fb48b9bd074e/Multi-Agent-Collaboration-in-AI-Enhancing-Software-Development-with-Autonomous-LLMs.pdf","The integration of multi-agent collaboration in artificial intelligence has the potential to revolutionize software development by leveraging autonomous large language models (LLMs) for enhanced efficiency, accuracy, and scalability. Traditional software engineering processes often rely on human collaboration, but the increasing complexity of modern development tasks necessitates more advanced automation. This study explores how multi-agent LLM systems can work collaboratively to streamline various aspects of software engineering, including requirement analysis, code generation, debugging, and documentation. By distributing tasks among specialized agents with unique expertise, these systems can improve software quality while reducing development time. Experimental results indicate that multi-agent LLM collaboration significantly enhances problem-solving capabilities, enabling the efficient resolution of complex coding challenges. Furthermore, the ability of these agents to communicate, refine outputs, and iteratively improve code contributes to higher levels of accuracy and consistency. Despite these advantages, challenges such as coordination overhead, security concerns, and bias propagation remain critical areas for further investigation. This research highlights the transformative potential of multi-agent LLMs in software engineering while emphasizing the need for robust governance frameworks to ensure responsible deployment.","2025","2025-05-22 20:00:52","2025-05-26 13:26:28","2025-05-22 20:00:28","","","","","","","Multi-Agent Collaboration in AI","","","","","","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8VV6W657","journalArticle","2025","Khan, Salman; Daviglus, Mendus","AI-Driven Automation in Agile Development: Multi-Agent LLMs for Software Engineering","","","","","https://www.researchgate.net/profile/Mendus-Daviglus/publication/388834977_AI-Driven_Automation_in_Agile_Development_Multi-Agent_LLMs_for_Software_Engineering/links/67a90985461fb56424d320a7/AI-Driven-Automation-in-Agile-Development-Multi-Agent-LLMs-for-Software-Engineering.pdf","The integration of AI-driven automation in agile software development has gained significant momentum, with large language models (LLMs) playing a crucial role in streamlining workflows. This study explores the potential of multi-agent LLM systems in enhancing various aspects of software engineering, including code generation, bug detection, documentation, and project management. By leveraging multiple specialized AI agents that collaborate dynamically, we analyze how automation can improve development efficiency while maintaining code quality and adaptability. Our research implements and evaluates a multi-agent framework, assessing its impact on sprint planning, automated testing, and continuous integration pipelines. Experimental results demonstrate that multi-agent LLMs can effectively reduce development time, enhance team productivity, and provide real-time decision support, making them valuable assets in agile environments. However, challenges such as model interpretability, error propagation, and alignment with human developers remain critical concerns. This study highlights the benefits and limitations of AI-driven automation in agile development and suggests future directions for optimizing multi-agent LLM frameworks for software engineering.","2025","2025-05-22 20:00:52","2025-05-26 13:20:41","2025-05-22 20:00:30","","","","","","","AI-Driven Automation in Agile Development","","","","","","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PNNIRIW8","conferencePaper","2024","Karaduman, Burak; Tezel, Baris Tekin; Kardas, Geylani; Challenger, Moharram","DSML4JaCaMo: A Modelling tool for Multi-agent Programming with JaCaMo","2024 19th Conference on Computer Science and Intelligence Systems (FedCSIS)","","","","https://ieeexplore.ieee.org/abstract/document/10736036/","This paper introduces a domain-specific modelling language (DSML) called DSML4JaCaMo to develop belief-desire-intention (BDI) agents. The DSML’s design covers aspects of Jason, Cartago, and Moise from viewpoints that follow the meta-modelling approach. In this way, the DSML4JaCaMo enables graphical modelling of JaCaMo’s multi-agent systems (MASs), providing comprehensive support for defining agents’ beliefs, desires, and intentions (BDI) using Jason, specifying artifacts and their operations with Cartago, and outlining organizational structures and norms via Moise. The DSML’s operational semantics ensure seamless integration of these components, facilitating automatic code generation and artifact construction for creating a JaCaMo-based system. The graphical syntax contributes to ease of use, making it accessible for novice and experienced developers. This work aims to enhance the JaCaMo ecosystem by offering a model-driven approach to provide abstraction on MAS development as well as facilitating design and implementation.","2024","2025-05-22 20:00:52","2025-05-26 13:23:38","2025-05-22 20:00:32","637–642","","","","","","DSML4JaCaMo","","","","","IEEE","","","","","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/ND7LX677/Karaduman et al. - 2024 - DSML4JaCaMo A Modelling tool for Multi-agent Programming with JaCaMo.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ALUWDMS4","journalArticle","2024","Zahid, Ismail; Hussain, Ijaz","Multi-Agent AI Collaboration: Advancing Software Engineering with Autonomous LLMs","","","","","https://www.researchgate.net/profile/Ijaz-Hussain-23/publication/388835227_Multi-Agent_AI_Collaboration_Advancing_Software_Engineering_with_Autonomous_LLMs/links/67a8fabd645ef274a478ae49/Multi-Agent-AI-Collaboration-Advancing-Software-Engineering-with-Autonomous-LLMs.pdf","The integration of multi-agent AI systems into software engineering is transforming traditional development workflows. Large Language Models (LLMs), when used collaboratively, enhance automation, streamline coding processes, and improve overall software quality. This paper explores the role of autonomous LLMs in multi-agent AI collaboration, focusing on their impact on code generation, debugging, project management, and software lifecycle optimization. Multiagent AI collaboration leverages distributed problem-solving, where multiple LLMs specialize in different aspects of software development. By automating repetitive tasks, such as writing boilerplate code and generating documentation, these AI agents reduce developer workload and enhance productivity. Additionally, they assist in identifying code inefficiencies, detecting security vulnerabilities, and refining algorithms with minimal human intervention. One of the key challenges in AI-driven software engineering is ensuring seamless communication and coordination among multiple agents. This paper examines techniques for optimizing multi-agent interactions, including reinforcement learning, agent-based task delegation, and contextual awareness. The research also highlights the ethical and practical considerations of AI in software engineering. While multi-agent LLMs offer significant advantages, challenges such as AI bias, hallucinations, and reliability must be addressed to ensure responsible AI adoption. By integrating explainability frameworks and human oversight mechanisms, organizations can leverage AI collaboration while maintaining accountability and transparency. This study concludes that multiagent AI systems are poised to revolutionize software engineering by enhancing automation, reducing development time, and improving software robustness.","2024","2025-05-22 20:00:52","2025-05-26 13:26:06","2025-05-22 20:00:34","","","","","","","Multi-Agent AI Collaboration","","","","","","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UGRMMQRT","journalArticle","2025","Akinboyewa, Temitope; Li, Zhenlong; Ning, Huan; Lessani, M. Naser","GIS Copilot: towards an autonomous GIS agent for spatial analysis","International Journal of Digital Earth","","1753-8947, 1753-8955","10.1080/17538947.2025.2497489","https://www.tandfonline.com/doi/full/10.1080/17538947.2025.2497489","Recent advancements in generative artificial intelligence (AI), particularly Large Language Models (LLMs), offer promising capabilities for spatial analysis. However, their integration with established GIS platforms remains underexplored. In this study, we propose a framework that embeds LLMs into existing GIS platforms, using QGIS as a case study. Our approach leverages LLMs’ reasoning and coding abilities to autonomously generate spatial analysis workflows through an informed agent equipped with comprehensive documentation of key GIS tools and parameters. External tools such as GeoPandas are also incorporated to enhance the system's geoprocessing capabilities. Based on this framework, we developed a ‘GIS Copilot’ that enables users to interact with QGIS using natural language. We evaluated the copilot across over 100 tasks of varying complexity including basic (single tool/layer), intermediate (multistep with guidance), and advanced (multistep without guidance). Results show high success rates for basic and intermediate tasks, with challenges remaining in fully autonomous execution of advanced tasks. The GIS Copilot advances the vision of autonomous GIS by enabling non-experts to perform geospatial analysis with minimal prior knowledge. While full autonomy is not yet achieved, the copilot demonstrates significant potential for simplifying GIS workflows and enhancing decision-making processes.","2025-12-31","2025-05-22 20:00:52","2025-05-26 13:25:03","2025-05-22 20:00:34","2497489","","1","18","","International Journal of Digital Earth","GIS Copilot","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/ksoares/Zotero/storage/96YVLN4N/Akinboyewa et al. - 2025 - GIS Copilot towards an autonomous GIS agent for spatial analysis.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BWD5AIZV","conferencePaper","2024","Ranga, Sriram; Mao, Rui; Bhattacharjee, Debjyoti; Cambria, Erik; Chattopadhyay, Anupam","RTL Agent: An Agent-Based Approach for Functionally Correct HDL Generation via LLMs","2024 IEEE 33rd Asian Test Symposium (ATS)","","","","https://ieeexplore.ieee.org/abstract/document/10915277/","LLMs as code generators have undergone rapid progress over the past couple of years. However, the models on their own provide no guarantees for the functional correctness of the generated code. Functional tests can not only be used by designers to assess the functional correctness of code, but also to guide them towards the solution of the problem. The same can be applied to LLMs performing automatic code generation through the use of the Reflexion technique. Reflexion is an agent-based workflow where the model generating code iterates over a loop of code generation, getting feedback from the test bench, reflecting on the feedback, and making appropriate changes to the code. The technique is known to drastically improve the performance of LLMs on software code generation. In this work, we adopt the technique for hardware description language (HDL) code generation as RTL Agent - an implementation of the workflow for Verilog generation with Reflexion. We compare multiple LLMs with standard inference vs with Reflexion on the VerilogEval benchmark. Within 5 iterations of the feedback loop, we observe a relative improvement of 33.2% for the low-performance model Llama3 and an average of 17.7% for the high-performance models GPT-4o and GPT-4o-mini in their Pass@1 performance. We present a cost analysis of the technique to enable cost-performance trade-offs.","2024","2025-05-22 20:00:52","2025-05-26 13:27:11","2025-05-22 20:00:36","1–6","","","","","","RTL Agent","","","","","IEEE","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BIAHZ3NW","preprint","2025","Li, Bingxuan; Wang, Yiwei; Gu, Jiuxiang; Chang, Kai-Wei; Peng, Nanyun","METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling","","","","10.48550/arXiv.2502.17651","http://arxiv.org/abs/2502.17651","Chart generation aims to generate code to produce charts satisfying the desired visual properties, e.g., texts, layout, color, and type. It has great potential to empower the automatic professional report generation in financial analysis, research presentation, education, and healthcare. In this work, we build a vision-language model (VLM) based multi-agent framework for effective automatic chart generation. Generating high-quality charts requires both strong visual design skills and precise coding capabilities that embed the desired visual properties into code. Such a complex multi-modal reasoning process is difficult for direct prompting of VLMs. To resolve these challenges, we propose METAL, a multi-agent framework that decomposes the task of chart generation into the iterative collaboration among specialized agents. METAL achieves 5.2% improvement over the current best result in the chart generation task. The METAL framework exhibits the phenomenon of test-time scaling: its performance increases monotonically as the logarithmic computational budget grows from 512 to 8192 tokens. In addition, we find that separating different modalities during the critique process of METAL boosts the self-correction capability of VLMs in the multimodal context.","2025-03-06","2025-05-22 20:00:52","2025-05-22 20:00:53","2025-05-22 20:00:38","","","","","","","METAL","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2502.17651 [cs]","","/Users/ksoares/Zotero/storage/NMTUT25K/Li et al. - 2025 - METAL A Multi-Agent Framework for Chart Generation with Test-Time Scaling.pdf; /Users/ksoares/Zotero/storage/IWCJ5MPL/2502.html","","","Computer Science - Computation and Language; Computer Science - Artificial Intelligence; Computer Science - Computer Vision and Pattern Recognition","","","","","","","","","","","","","","","","","","","arXiv:2502.17651","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"US7DTKAU","conferencePaper","2024","Vallecillos Ruiz, Fernando","Agent-Driven Automatic Software Improvement","Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering","979-8-4007-1701-7","","10.1145/3661167.3661171","https://dl.acm.org/doi/10.1145/3661167.3661171","With software maintenance accounting for 50% of the cost of developing software, enhancing code quality and reliability has become more critical than ever. In response to this challenge, this doctoral research proposal aims to explore innovative solutions by focusing on the deployment of agents powered by Large Language Models (LLMs) to perform software maintenance tasks. The iterative nature of agents, which allows for continuous learning and adaptation, can help surpass common challenges in code generation. One distinct challenge is the last-mile problems, errors at the final stage of producing functionally and contextually relevant code. Furthermore, this project aims to surpass the inherent limitations of current LLMs in source code through a collaborative framework where agents can correct and learn from each other’s errors. We aim to use the iterative feedback in these systems to further fine-tune the LLMs underlying the agents, becoming better aligned to the task of automated software improvement. Our main goal is to achieve a leap forward in the field of automatic software improvement by developing new tools and frameworks that can enhance the efficiency and reliability of software development.","2024-06-18","2025-05-22 20:00:52","2025-05-26 13:19:58","2025-05-22 20:00:40","470-475","","","","","","","","","","","ACM","Salerno Italy","en","","","","","DOI.org (Crossref)","","","","/Users/ksoares/Zotero/storage/HG84XDYZ/Vallecillos Ruiz - 2024 - Agent-Driven Automatic Software Improvement.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","EASE 2024: 28th International Conference on Evaluation and Assessment in Software Engineering","","","","","","","","","","","","","","",""
"49H7P5WN","journalArticle","2025","Nasir, Waseem; Kallinteris, Nikoletta","From Code Generation to AI Collaboration: The Role of Multi-Agent Systems in Software Engineering","","","","","https://www.researchgate.net/profile/Nikoletta-Kallinteris/publication/388835330_From_Code_Generation_to_AI_Collaboration_The_Role_of_Multi-Agent_Systems_in_Software_Engineering/links/67a900d9207c0c20fa81a501/From-Code-Generation-to-AI-Collaboration-The-Role-of-Multi-Agent-Systems-in-Software-Engineering.pdf","The integration of multi-agent systems (MAS) in software engineering is revolutionizing the way developers interact with artificial intelligence, shifting from simple code generation to sophisticated AI-driven collaboration. Multi-agent systems, powered by large language models (LLMs), enable distributed problem-solving, automated workflow optimization, and enhanced decision-making in software development. These AI agents operate autonomously, coordinating tasks such as debugging, documentation, and requirement analysis while seamlessly integrating with human developers. By leveraging reinforcement learning, knowledge representation, and adaptive learning mechanisms, MAS enhances productivity and reduces cognitive load in complex software projects. This study explores the role of multi-agent AI systems in software engineering, analyzing their impact on development efficiency, code quality, and team collaboration. We investigate various AI-driven frameworks, contrasting their capabilities with traditional software engineering methodologies. Our findings indicate that MAS fosters a more dynamic and intelligent software development process, facilitating real-time issue resolution and adaptive coding strategies. However, challenges such as model interpretability, AI bias, and ethical concerns must be addressed to ensure responsible deployment.","2025","2025-05-22 20:00:52","2025-05-26 13:24:44","2025-05-22 20:00:40","","","","","","","From Code Generation to AI Collaboration","","","","","","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SKA6XLQJ","conferencePaper","2024","Chen, John; Lu, Xi; Du, Yuzhou; Rejtig, Michael; Bagley, Ruth; Horn, Mike; Wilensky, Uri","Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT & NetLogo Chat","Proceedings of the CHI Conference on Human Factors in Computing Systems","979-8-4007-0330-0","","10.1145/3613904.3642377","https://dl.acm.org/doi/10.1145/3613904.3642377","Large Language Models (LLMs) have the potential to fundamentally change the way people engage in computer programming. Agent-based modeling (ABM) has become ubiquitous in natural and social sciences and education, yet no prior studies have explored the potential of LLMs to assist it. We designed NetLogo Chat to support the learning and practice of NetLogo, a programming language for ABM. To understand how users perceive, use, and need LLM-based interfaces, we interviewed 30 participants from global academia, industry, and graduate schools. Experts reported more perceived benefits than novices and were more inclined to adopt LLMs in their workflow. We found significant differences between experts and novices in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced a knowledge gap between experts and novices as a possible reason for the benefit gap. We identified guidance, personalization, and integration as major needs for LLM-based interfaces to support the programming of ABM.","2024-05-11","2025-05-22 20:00:52","2025-05-26 13:25:33","2025-05-22 20:00:44","1-18","","","","","","Learning Agent-based Modeling with LLM Companions","","","","","ACM","Honolulu HI USA","en","","","","","DOI.org (Crossref)","","","","/Users/ksoares/Zotero/storage/5B2K5EDS/Chen et al. - 2024 - Learning Agent-based Modeling with LLM Companions Experiences of Novices and Experts Using ChatGPT.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","CHI '24: CHI Conference on Human Factors in Computing Systems","","","","","","","","","","","","","","",""
"DA5C9M8V","conferencePaper","2025","Rajendran, Vasanth; Besiahgari, Dinesh; Patil, Sachin C.; Chandrashekaraiah, Manjunath; Challagulla, Vishnu","A Multi-Agent LLM Environment for Software Design and Refactoring: A Conceptual Framework","SoutheastCon 2025","","","","https://ieeexplore.ieee.org/abstract/document/10971563/","Modern software systems demand continuous evolution to maintain performance, scalability, and security. Traditional single-agent AI-driven code refactoring approaches are often limited in addressing the multi-faceted constraints (e.g., performance, security, maintainability) that emerge during complex software design tasks. In this paper, we propose a novel Multi-Agent Large Language Model (LLM) Environment for automated software design and refactoring. Our conceptual framework comprises specialized LLM “experts,” each trained or fine-tuned on a different aspect of software engineering (performance optimization, security hardening, UI/UX, maintainability). These agents collaborate in a cooperative or competitive fashion-using coordination protocols akin to consensus or auction mechanisms-to synthesize design insights and refactoring recommendations. We present formal definitions of agent interactions (including mathematical notation for termination conditions), a sequence diagram demonstrating agent collaboration, a complexity analysis of the coordination mechanism, and an expanded reference list. Preliminary experimental design is outlined to demonstrate how multi-agent interactions may resolve conflicting design goals more effectively than a single-agent approach. Our aim is to provide a roadmap for integrating multi-agent LLMs into the software development lifecycle, thereby improving development efficiency, reducing technical debt, and enhancing software quality.","2025","2025-05-22 20:00:52","2025-05-26 13:19:23","2025-05-22 20:00:46","488–493","","","","","","A Multi-Agent LLM Environment for Software Design and Refactoring","","","","","IEEE","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EX276C7Y","journalArticle","2024","Abbas, Ghulam; Wahab, Abdul","AI-Driven Agile Development: How Multi-Agent LLMs Optimize Engineering Workflows","","","","","https://www.researchgate.net/profile/Abdul-Wahab-207/publication/388834911_AI-Driven_Agile_Development_How_Multi-Agent_LLMs_Optimize_Engineering_Workflows/links/67a8f79c645ef274a478ad7c/AI-Driven-Agile-Development-How-Multi-Agent-LLMs-Optimize-Engineering-Workflows.pdf","AI-driven Agile development is transforming engineering workflows by integrating multi-agent Large Language Models (LLMs) to enhance collaboration, automation, and decision-making. Traditional Agile methodologies rely on iterative development, rapid feedback, and continuous improvement, but AI-powered multi-agent systems optimize these processes by automating repetitive tasks, analyzing vast datasets, and providing intelligent recommendations. Multi-agent LLMs function as autonomous entities capable of handling various aspects of software development, including code generation, bug detection, requirement analysis, and project management. By leveraging these AI-driven agents, teams can accelerate development cycles, reduce human errors, and improve overall software quality. These models also facilitate real-time collaboration by processing vast amounts of information, summarizing key insights, and optimizing sprint planning. One of the critical advantages of AI-driven Agile development is enhanced efficiency. Automated backlog prioritization, intelligent risk assessment, and real-time code reviews allow engineering teams to focus on innovation rather than manual administrative tasks. Multi-agent systems improve workflow coordination by distributing workloads dynamically based on project demands and developer expertise, ensuring optimal resource allocation. Despite these benefits, integrating AI-driven multi-agent LLMs into Agile development presents challenges, including ethical considerations, data security risks, and maintaining human oversight. Ensuring transparency, interpretability, and ethical AI usage is essential for successful implementation. Moreover, AI models require continuous updates to adapt to evolving development needs and maintain accuracy in recommendations.","2024","2025-05-22 20:00:52","2025-05-26 13:20:25","2025-05-22 20:00:50","","","","","","","AI-Driven Agile Development","","","","","","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"56GXX6J5","conferencePaper","2024","Garlapati, Anusha; Parmesh, MNV Satya Sai Muni","AI-Powered Multi-Agent Framework for Automated Unit Test Case Generation: Enhancing Software Quality through LLM’s","2024 5th IEEE Global Conference for Advancement in Technology (GCAT)","","","","https://ieeexplore.ieee.org/abstract/document/10923987/","Recent years have witnessed an enormous rise in the design, repair and the enhancement of software automation tests. The reliability of program’s unit testing has major impact on its overall performance. The anticipated influence of Artificial Intelligence advancements on test automation methodologies are significant. Many studies on automated testing implicitly assume that the test results are deterministic, means that similar tests faults remain same. The precision of software is largely ensured by unit testing. But writing unit tests manually is a time-consuming process, which leads us to drive into ""Automation Analysis"". Recent years comprised the application of Large Language Models (LLM’s) in numerous fields related to software development, especially the automated creation of unit testing.However, these frameworks require more instructions, or few shot learnings on sample tests that already exist. This research provides a comprehensive empirical assessment of the efficiency of LLM’s for automating unit testing production, with no need for further manual analysis. The method we employ is put into practice for test cases, an adaptable Agents and LLM-based testing framework that evaluates test cases generated, by reviewing and re-writing them in different phases. Evaluation of this test cases was done by using mistral-large LLM Model. The analysis results that developed acquired an overall coverage of 100% for code given. Finally, to enhance the typical evaluation, this research suggests and concludes that LLMs, can be successfully incorporated into present practices, through adaptative instructions and improvements.","2024","2025-05-22 20:00:52","2025-05-26 13:20:48","2025-05-22 20:00:52","1–5","","","","","","AI-Powered Multi-Agent Framework for Automated Unit Test Case Generation","","","","","IEEE","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T8YN6PAG","preprint","2025","Pan, Ruwei; Zhang, Hongyu; Liu, Chao","CodeCoR: An LLM-Based Self-Reflective Multi-Agent Framework for Code Generation","","","","10.48550/arXiv.2501.07811","http://arxiv.org/abs/2501.07811","Code generation aims to produce code that fulfills requirements written in natural languages automatically. Large language Models (LLMs) like ChatGPT have demonstrated promising effectiveness in this area. Nonetheless, these LLMs often fail to ensure the syntactic and semantic correctness of the generated code. Recently, researchers proposed multi-agent frameworks that guide LLMs with different prompts to analyze programming tasks, generate code, perform testing in a sequential workflow. However, the performance of the workflow is not robust as the code generation depends on the performance of each agent. To address this challenge, we propose CodeCoR, a self-reflective multi-agent framework that evaluates the effectiveness of each agent and their collaborations. Specifically, for a given task description, four agents in CodeCoR generate prompts, code, test cases, and repair advice, respectively. Each agent generates more than one output and prunes away the low-quality ones. The generated code is tested in the local environment: the code that fails to pass the generated test cases is sent to the repair agent and the coding agent re-generates the code based on repair advice. Finally, the code that passes the most number of generated test cases is returned to users. Our experiments on four widely used datasets, HumanEval, HumanEval-ET, MBPP, and MBPP-ET, demonstrate that CodeCoR significantly outperforms existing baselines (e.g., CodeCoT and MapCoder), achieving an average Pass@1 score of 77.8%.","2025-01-14","2025-05-22 20:02:37","2025-05-22 20:02:37","2025-05-22 20:02:00","","","","","","","CodeCoR","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2501.07811 [cs]","","/Users/ksoares/Zotero/storage/AXZK53PG/Pan et al. - 2025 - CodeCoR An LLM-Based Self-Reflective Multi-Agent Framework for Code Generation.pdf; /Users/ksoares/Zotero/storage/D7HUPZM4/2501.html","","","Computer Science - Software Engineering","","","","","","","","","","","","","","","","","","","arXiv:2501.07811","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZT82VVAA","preprint","2025","Wang, Xiao; Dong, Lu; Rangasrinivasan, Sahana; Nwogu, Ifeoma; Setlur, Srirangaraj; Govindaraju, Venugopal","AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in the Misty Social Robot","","","","10.48550/arXiv.2503.06791","http://arxiv.org/abs/2503.06791","The social robot's open API allows users to customize open-domain interactions. However, it remains inaccessible to those without programming experience. In this work, we introduce AutoMisty, the first multi-agent collaboration framework powered by large language models (LLMs), to enable the seamless generation of executable Misty robot code from natural language instructions. AutoMisty incorporates four specialized agent modules to manage task decomposition, assignment, problem-solving, and result synthesis. Each agent incorporates a two-layer optimization mechanism, with self-reflection for iterative refinement and human-in-the-loop for better alignment with user preferences. AutoMisty ensures a transparent reasoning process, allowing users to iteratively refine tasks through natural language feedback for precise execution. To evaluate AutoMisty's effectiveness, we designed a benchmark task set spanning four levels of complexity and conducted experiments in a real Misty robot environment. Extensive evaluations demonstrate that AutoMisty not only consistently generates high-quality code but also enables precise code control, significantly outperforming direct reasoning with ChatGPT-4o and ChatGPT-o1. All code, optimized APIs, and experimental videos will be publicly released through the webpage: https://wangxiaoshawn.github.io/AutoMisty.html","2025-03-09","2025-05-22 20:02:37","2025-05-22 20:02:37","2025-05-22 20:02:03","","","","","","","AutoMisty","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2503.06791 [cs]","","/Users/ksoares/Zotero/storage/7DJ5LCLC/Wang et al. - 2025 - AutoMisty A Multi-Agent LLM Framework for Automated Code Generation in the Misty Social Robot.pdf; /Users/ksoares/Zotero/storage/A942C7LC/2503.html","","","Computer Science - Artificial Intelligence; Computer Science - Multiagent Systems; Computer Science - Human-Computer Interaction; Computer Science - Robotics","","","","","","","","","","","","","","","","","","","arXiv:2503.06791","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"67WZF8NB","journalArticle","2024","Tao, Wei; Zhou, Yucheng; Wang, Yanlin; Zhang, Wenqiang; Zhang, Hongyu; Cheng, Yu","Magis: Llm-based multi-agent framework for github issue resolution","Advances in Neural Information Processing Systems","","","","https://proceedings.neurips.cc/paper_files/paper/2024/hash/5d1f02132ef51602adf07000ca5b6138-Abstract-Conference.html","In software development, resolving the emergent issues within GitHub repositories is a complex challenge that involves not only the incorporation of new code but also the maintenance of existing code.Large Language Models (LLMs) have shown promise in code generation but face difficulties in resolving Github issues, particularly at the repository level. To overcome this challenge, we empirically study the reason why LLMs fail to resolve GitHub issues and analyze the major factors. Motivated by the empirical findings, we propose a novel LLM-based Multi-Agent framework for GitHub Issue reSolution, MAGIS, consisting of four agents customized for software evolution: Manager, Repository Custodian, Developer, and Quality Assurance Engineer agents. This framework leverages the collaboration of various agents in the planning and coding process to unlock the potential of LLMs to resolve GitHub issues. In experiments, we employ the SWE-bench benchmark to compare MAGIS with popular LLMs, including GPT-3.5, GPT-4, and Claude-2. MAGIS can resolve 13.94% GitHub issues, significantly outperforming the baselines.Specifically, MAGIS achieves an eight-fold increase in resolved ratio over the direct application of GPT-4, the advanced LLM.","2024","2025-05-22 20:02:37","2025-05-26 13:25:43","2025-05-22 20:02:07","51963–51993","","","37","","","Magis","","","","","","","","","","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/PP2XNZ77/Tao et al. - 2024 - Magis Llm-based multi-agent framework for github issue resolution.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RRN9BWU","preprint","2025","Nainani, Jatin; Ho, Chia-Tung; Dhurka, Anirudh; Ren, Haoxing","Timing Analysis Agent: Autonomous Multi-Corner Multi-Mode (MCMM) Timing Debugging with Timing Debug Relation Graph","","","","10.48550/arXiv.2504.11502","http://arxiv.org/abs/2504.11502","Timing analysis is an essential and demanding verification method for Very Large Scale Integrated (VLSI) circuit design and optimization. In addition, it also serves as the cornerstone of the final sign-off, determining whether the chip is ready to be sent to the semiconductor foundry for fabrication. Recently, as the technology advance relentlessly, smaller metal pitches and the increasing number of devices have led to greater challenges and longer turn-around-time for experienced human designers to debug timing issues from the Multi-Corner Multi-Mode (MCMM) timing reports. As a result, an efficient and intelligent methodology is highly necessary and essential for debugging timing issues and reduce the turnaround times. Recently, Large Language Models (LLMs) have shown great promise across various tasks in language understanding and interactive decision-making, incorporating reasoning and actions. In this work, we propose a timing analysis agent, that is empowered by multi-LLMs task solving, and incorporates a novel hierarchical planning and solving flow to automate the analysis of timing reports from commercial tool. In addition, we build a Timing Debug Relation Graph (TDRG) that connects the reports with the relationships of debug traces from experienced timing engineers. The timing analysis agent employs the novel Agentic Retrieval Augmented Generation (RAG) approach, that includes agent and coding to retrieve data accurately, on the developed TDRG. In our studies, the proposed timing analysis agent achieves an average 98% pass-rate on a single-report benchmark and a 90% pass-rate for multi-report benchmark from industrial designs, demonstrating its effectiveness and adaptability.","2025-04-15","2025-05-22 20:02:37","2025-05-22 20:02:37","2025-05-22 20:02:09","","","","","","","Timing Analysis Agent","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2504.11502 [cs]","","/Users/ksoares/Zotero/storage/LBU4P2CQ/Nainani et al. - 2025 - Timing Analysis Agent Autonomous Multi-Corner Multi-Mode (MCMM) Timing Debugging with Timing Debug.pdf; /Users/ksoares/Zotero/storage/YIXSI79R/2504.html","","","Computer Science - Software Engineering; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2504.11502","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y6VIAYGN","conferencePaper","2025","Akilesh, S.; Sekar, Rajeev; CU, Om Kumar; Prakalya, D.; Suguna, M.","Multi-Agent hierarchical workflow for autonomous code generation with Large Language Models","2025 IEEE International Students' Conference on Electrical, Electronics and Computer Science (SCEECS)","","","","https://ieeexplore.ieee.org/abstract/document/10940635/","This paper presents a multi-agent hierarchical workflow tailored for automating data analysis, code generation, and visualization, focusing specifically on user-provided CSV datasets. The workflow integrates AlphaCodium with LangChain, LangGraph, and GPT, enabling autonomous code generation, unit test development, and debugging. The system operates by analyzing the uploaded dataset, assigning agents that work sequentially: a programmer agent generates code using the Skeleton-Of-Code approach, a unit test agent verifies the code, and an executor agent runs the code. A debugging agent is also included to identify and resolve any issues. The AI agents involved are capable of dynamically accessing online resources, including documentation and references to enhance their decision-making processes. This work attempts to exemplify the application of AI in automating not only code execution but also the planning and validation stages by writing unit tests in the software development process to reflect the increasing role of AI in advancing automation for rapid code generation within the software industry.","2025","2025-05-22 20:02:37","2025-05-26 13:26:35","2025-05-22 20:02:10","1–5","","","","","","","","","","","IEEE","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8QU27S4T","preprint","2025","Siddeeq, Shahbaz; Rasheed, Zeeshan; Sami, Malik Abdul; Hasan, Mahade; Waseem, Muhammad; Rasku, Jussi; Saari, Mika; Kemell, Kai-Kristian; Abrahamsson, Pekka","Distributed Approach to Haskell Based Applications Refactoring with LLMs Based Multi-Agent Systems","","","","10.48550/arXiv.2502.07928","http://arxiv.org/abs/2502.07928","We present a large language models (LLMs) based multi-agent system to automate the refactoring of Haskell codebases. The multi-agent system consists of specialized agents performing tasks such as context analysis, refactoring, validation, and testing. Refactoring improvements are using metrics such as cyclomatic complexity, run-time, and memory allocation. Experimental evaluations conducted on Haskell codebases demonstrate improvements in code quality. Cyclomatic complexity was reduced by 13.64% and 47.06% in the respective codebases. Memory allocation improved by 4.17% and 41.73%, while runtime efficiency increased by up to 50%. These metrics highlight the systems ability to optimize Haskells functional paradigms while maintaining correctness and scalability. Results show reductions in complexity and performance enhancements across codebases. The integration of LLMs based multi-agent system enables precise task execution and inter-agent collaboration, addressing the challenges of refactoring in functional programming. This approach aims to address the challenges of refactoring functional programming languages through distributed and modular systems.","2025-02-11","2025-05-22 20:02:37","2025-05-22 20:02:37","2025-05-22 20:02:11","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2502.07928 [cs]","","/Users/ksoares/Zotero/storage/SF7YCY6Z/Siddeeq et al. - 2025 - Distributed Approach to Haskell Based Applications Refactoring with LLMs Based Multi-Agent Systems.pdf; /Users/ksoares/Zotero/storage/8SJMC5W3/2502.html","","","Computer Science - Software Engineering","","","","","","","","","","","","","","","","","","","arXiv:2502.07928","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PJ4Y3VVJ","journalArticle","","Kurunthachalam, Aravindhan","Enhancing AI-Driven Software Optimization with Attention-Based Memory Transformers and Graph Multi-Agent RL","","","","","http://ijses.com/wp-content/uploads/2025/03/40-IJSES-V9N3.pdf","In the evolving field of AI system software optimization, accomplishing efficient performance management remains a critical task. The paper introduces a new trifecta framework for Memory-Augmented Transformers with GNNs and MARL algorithms, which is essentially the next logical step in addressing performance management challenges in AI systems. Most of the techniques used so far include MANNs + HMAL + CBMs, and thus none of these approaches are sufficiently competent in retaining memory, achieving complete coordination, and demonstrating flexibility, causing wastage of underutilized resources and functionality of the system. This framework lacks limitations such as dynamic allocation of resources, better workload balancing, and accurate anomaly detection. The results are stupendous, with improvements in memory retention efficiency at 95 percent, coordination accuracy at 94 percent, adaptability at 92 percent, and task completion rate at 96 percent. The model further improves the system's efficiency by 25 percent, resource utilization at 92 percent, and detects an anomaly with an F1-Score of 0.93 and ROCAUC of 0.96, calculated over a significant amount of time. It proves superior to MANNs + HMAL + CBMs across the board, which differentiates it from other existing algorithms for use in systems management. This hybrid framework also has enormous potential application areas in the future, such as IoT, autonomous vehicles, and smart cities, with the work looking into integrating it into an edge computing framework to scale further.","","2025-05-22 20:02:37","2025-05-26 13:23:55","2025-05-22 20:02:11","","","","","","","","","","","","","","","","","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/N57CDVT2/Kurunthachalam - Enhancing AI-Driven Software Optimization with Attention-Based Memory Transformers and Graph Multi-A.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RJLL435P","preprint","2024","Ren, Siyue; Cui, Zhiyao; Song, Ruiqi; Wang, Zhen; Hu, Shuyue","Emergence of Social Norms in Generative Agent Societies: Principles and Architecture","","","","10.48550/arXiv.2403.08251","http://arxiv.org/abs/2403.08251","Social norms play a crucial role in guiding agents towards understanding and adhering to standards of behavior, thus reducing social conflicts within multi-agent systems (MASs). However, current LLM-based (or generative) MASs lack the capability to be normative. In this paper, we propose a novel architecture, named CRSEC, to empower the emergence of social norms within generative MASs. Our architecture consists of four modules: Creation & Representation, Spreading, Evaluation, and Compliance. This addresses several important aspects of the emergent processes all in one: (i) where social norms come from, (ii) how they are formally represented, (iii) how they spread through agents' communications and observations, (iv) how they are examined with a sanity check and synthesized in the long term, and (v) how they are incorporated into agents' planning and actions. Our experiments deployed in the Smallville sandbox game environment demonstrate the capability of our architecture to establish social norms and reduce social conflicts within generative MASs. The positive outcomes of our human evaluation, conducted with 30 evaluators, further affirm the effectiveness of our approach. Our project can be accessed via the following link: https://github.com/sxswz213/CRSEC.","2024-08-30","2025-05-22 20:02:37","2025-05-22 20:02:37","2025-05-22 20:02:15","","","","","","","Emergence of Social Norms in Generative Agent Societies","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2403.08251 [cs]","","/Users/ksoares/Zotero/storage/Q395S8RY/Ren et al. - 2024 - Emergence of Social Norms in Generative Agent Societies Principles and Architecture.pdf; /Users/ksoares/Zotero/storage/HNNC7NS6/2403.html","","","Computer Science - Artificial Intelligence; Computer Science - Multiagent Systems; Computer Science - Computers and Society","","","","","","","","","","","","","","","","","","","arXiv:2403.08251","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NBMV35J5","conferencePaper","2024","Sun, Jinyuan; Li, Auston; Deng, Yifan; Li, Jiabo","ChatMol Copilot: An Agent for Molecular Modeling and Computation Powered by LLMs","Proceedings of the 1st Workshop on Language+ Molecules (L+ M 2024)","","","","https://aclanthology.org/2024.langmol-1.7/","Large Language Models (LLMs) like ChatGPT excel at diverse tasks when given explicit instructions, yet they often struggle with specialized domains such as molecular science, lacking in-depth reasoning and sophisticated planning capabilities. To address these limitations, we introduce ChatMol Copilot, a chatbot-like agent specifically engineered for protein design and small molecule computations. ChatMol Copilot employs a multi-level abstraction framework to expand the LLM‘s capability. At the basic level, it integrates external computational tools through function calls, thus offloading complex tasks and enabling a focus on strategic decision-making. The second level is data abstraction. Large data sets (such as a large number of molecules created by a generative model) are stored in Redis cache, and the redis keys are referenced by LLMs for data sources involved in computation. The third level of abstraction allows the LLM to orchestrate these tools, either directly or via dynamically generated Python executables. Our evaluations demonstrate that ChatMol Copilot can adeptly manage molecular modeling tasks, effectively utilizing a variety of tools as directed. By simplifying access to sophisticated molecular modeling resources, ChatMol Copilot stands to significantly accelerate drug discovery and biotechnological innovation, empowering biochemists with advanced, user-friendly AI capabilities. The open-sourced code is available at https://github.com/ChatMol/ChatMol","2024","2025-05-22 20:02:37","2025-05-26 13:21:19","2025-05-22 20:02:18","55–65","","","","","","ChatMol Copilot","","","","","","","","","","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/5ZXMSRLY/Sun et al. - 2024 - ChatMol Copilot An Agent for Molecular Modeling and Computation Powered by LLMs.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BMZFGW9T","preprint","2024","Rasheed, Zeeshan; Sami, Malik Abdul; Kemell, Kai-Kristian; Waseem, Muhammad; Saari, Mika; Systä, Kari; Abrahamsson, Pekka","CodePori: Large-Scale System for Autonomous Software Development Using Multi-Agent Technology","","","","10.48550/arXiv.2402.01411","http://arxiv.org/abs/2402.01411","Context: Large Language Models (LLMs) and Generative Pre-trained Transformers (GPTs) have transformed the field of Software Engineering (SE). Existing LLM-based multi-agent models have successfully addressed basic dialogue tasks. However, the potential of LLMs for more challenging tasks, such as automated code generation for large and complex projects, has been investigated in only a few existing works. Objective: This paper aims to investigate the potential of LLM-based agents in the software industry, particularly in enhancing productivity and reducing time-to-market for complex software solutions. Our primary objective is to gain insights into how these agents can fundamentally transform the development of large-scale software. Methods: We introduce CodePori, a novel system designed to automate code generation for large and complex software projects based on functional and non-functional requirements defined by stakeholders. To assess the proposed system performance, we utilized the HumanEval benchmark and manually tested the CodePori model, providing 20 different project descriptions as input and then evaluated the code accuracy by manually executing the code. Results: CodePori is able to generate running code for large-scale projects, aligned with the typical software development process. The HumanEval benchmark results indicate that CodePori improves code accuracy by 89%. A manual assessment conducted by the first author shows that the CodePori system achieved an accuracy rate of 85%. Conclusion: Based on the results, our conclusion is that proposed system demonstrates the transformative potential of LLM-based agents in SE, highlighting their practical applications and opening new opportunities for broader adoption in both industry and academia. Our project is publicly available at https://github.com/GPT-Laboratory/CodePori.","2024-09-17","2025-05-22 20:02:37","2025-05-22 20:02:37","2025-05-22 20:02:19","","","","","","","CodePori","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2402.01411 [cs]","","/Users/ksoares/Zotero/storage/W4WK242D/Rasheed et al. - 2024 - CodePori Large-Scale System for Autonomous Software Development Using Multi-Agent Technology.pdf; /Users/ksoares/Zotero/storage/PKLS5372/2402.html","","","Computer Science - Software Engineering","","","","","","","","","","","","","","","","","","","arXiv:2402.01411","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K8DKUH8P","journalArticle","2025","Li, Taochang; Chen, Zixuan; Hou, Limin","Speed Synchronization of Multi-PMSMs with Multi-Agent Prescribed-Time Sliding Mode Consensus Control","IEEE Journal of Emerging and Selected Topics in Power Electronics","","","","https://ieeexplore.ieee.org/abstract/document/10969797/","To improve the flexibility, accuracy and robustness of speed synchronization control among multiple permanent magnet synchronous motors (multi-PMSMs), research on multi-agent prescribed-time sliding mode consensus control is conducted in this paper. First, this work establishes the speed regulation system of multi-PMSMs as a multi-agent system (MAS) and then transforms the speed synchronization challenge into a consensus control problem in MAS, enabling information exchange via undirected graph communication topologies. Subsequently, a novel smooth terminal time regulator (S-TTR) function is designed, and a global prescribed-time time-varying sliding mode (TVSM) consensus control strategy incorporating the S-TTR function is proposed. The strategy ensures prescribed-time speed synchronization with enhanced control precision and robustness. Furthermore, a dual-layer adaptive prescribed-time disturbance observer (PTDO) is introduced to estimate disturbances within a prescribed time frame, addressing unknown upper bounds of disturbance derivatives. Additionally, the stability of both the controller and observer is proven using Lyapunov stability theory. Finally, comprehensive experiments validate the effectiveness and superiority of the proposed control strategy for multi-PMSMs systems.","2025","2025-05-22 20:02:37","2025-05-26 13:27:32","2025-05-22 20:02:22","","","","","","","","","","","","","","","","","","","Google Scholar","","Publisher: IEEE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MY3SNE85","conferencePaper","2024","Xie, Liwenhan; Zheng, Chengbo; Xia, Haijun; Qu, Huamin; Zhu-Tian, Chen","WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization","Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology","979-8-4007-0628-8","","10.1145/3654777.3676374","https://dl.acm.org/doi/10.1145/3654777.3676374","Large language models (LLMs) support data analysis through conversational user interfaces, as exemplified in OpenAI’s ChatGPT (formally known as Advanced Data Analysis or Code Interpreter). Essentially, LLMs produce code for accomplishing diverse analysis tasks. However, presenting raw code can obscure the logic and hinder user verification. To empower users with enhanced comprehension and augmented control over analysis conducted by LLMs, we propose a novel approach to transform LLM-generated code into an interactive visual representation. In the approach, users are provided with a clear, step-by-step visualization of the LLM-generated code in real time, allowing them to understand, verify, and modify individual data operations in the analysis. Our design decisions are informed by a formative study (N=8) probing into user practice and challenges. We further developed a prototype named WaitGPT and conducted a user study (N=12) to evaluate its usability and effectiveness. The findings from the user study reveal that WaitGPT facilitates monitoring and steering of data analysis performed by LLMs, enabling participants to enhance error detection and increase their overall confidence in the results.","2024-10-13","2025-05-22 20:02:37","2025-05-26 13:29:57","2025-05-22 20:02:24","1-14","","","","","","WaitGPT","","","","","ACM","Pittsburgh PA USA","en","","","","","DOI.org (Crossref)","","","","/Users/ksoares/Zotero/storage/7SL7NS2K/Xie et al. - 2024 - WaitGPT Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visu.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","UIST '24: The 37th Annual ACM Symposium on User Interface Software and Technology","","","","","","","","","","","","","","",""
"NW9C9EPR","conferencePaper","2024","Dong, Yuji; Zhang, Shiyao; Yao, Xueyan; Zhang, Jie; Huang, Sida; Li, Yue","Active Collaboration in IoT: Cognitive-agent Oriented Resource-centric Architecture","IEEE 2024 33rd International Conference on Computer Communications and Networks (ICCCN)","","","","https://www.researchgate.net/profile/Yuji-Dong-2/publication/384291958_Active_Collaboration_in_IoT_Cognitive-agent_Oriented_Resource-centric_Architecture/links/66f300f8906bca2ac3c8a3e4/Active-Collaboration-in-IoT-Cognitive-agent-Oriented-Resource-centric-Architecture.pdf","The Internet of Things (IoT) has emerged as a transformative technology, but its full potential remains unrealized due to challenges such as unclear and dynamic requirements, lack of standardized protocols, and the need for agile development approaches. To address these obstacles, this paper introduces the Cognitive-agent Oriented Resource-centric Architecture (CORA), a novel architecture designed to enhance the development of IoT systems. CORA employs an Active Collaboration paradigm that facilitates the autonomous interplay of intermediate services, enabling the instantiation of complex business logic without the need for exhaustive requirement analyses. The architecture comprises Cognitive Agents that leverage Large Language Models (LLMs) to comprehend their capabilities and resources, establish collaborations, and generate new services. By employing CORA, IoT developers can prioritize creating robust and flexible services, thereby fostering a more agile and responsive evolution of IoT ecosystems. The paper presents a case study demonstrating the application of CORA in a smart home scenario, showcasing the benefits of the Active Collaboration paradigm.","2024","2025-05-22 20:02:37","2025-05-26 13:19:45","2025-05-22 20:02:26","","","","","","","Active Collaboration in IoT","","","","","","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IJDIE7VC","journalArticle","2025","Jeong, Cheonsu","Beyond Text: Implementing Multimodal Large Language Model-Powered Multi-Agent Systems Using a No-Code Platform","Journal of Intelligence and Information Systems","","2288-4866, 2288-4882","10.13088/jiis.2025.31.1.191","http://arxiv.org/abs/2501.00750","This study proposes the design and implementation of a multimodal LLM-based Multi-Agent System (MAS) leveraging a No-Code platform to address the practical constraints and significant entry barriers associated with AI adoption in enterprises. Advanced AI technologies, such as Large Language Models (LLMs), often pose challenges due to their technical complexity and high implementation costs, making them difficult for many organizations to adopt. To overcome these limitations, this research develops a No-Code-based Multi-Agent System designed to enable users without programming knowledge to easily build and manage AI systems. The study examines various use cases to validate the applicability of AI in business processes, including code generation from image-based notes, Advanced RAG-based question-answering systems, text-based image generation, and video generation using images and prompts. These systems lower the barriers to AI adoption, empowering not only professional developers but also general users to harness AI for significantly improved productivity and efficiency. By demonstrating the scalability and accessibility of No-Code platforms, this study advances the democratization of AI technologies within enterprises and validates the practical applicability of Multi-Agent Systems, ultimately contributing to the widespread adoption of AI across various industries.","2025-03-31","2025-05-22 20:02:37","2025-05-22 20:02:37","2025-05-22 20:02:26","191-231","","1","31","","jiis","Beyond Text","","","","","","","","","","","","arXiv.org","","arXiv:2501.00750 [cs]","","/Users/ksoares/Zotero/storage/YBKLW7NA/Jeong - 2025 - Beyond Text Implementing Multimodal Large Language Model-Powered Multi-Agent Systems Using a No-Cod.pdf; /Users/ksoares/Zotero/storage/RUGR9HFG/2501.html","","","Computer Science - Artificial Intelligence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2HM5T7F7","preprint","2025","Xiang, Yanzheng; Yan, Hanqi; Ouyang, Shuyin; Gui, Lin; He, Yulan","SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers","","","","10.48550/arXiv.2504.00255","http://arxiv.org/abs/2504.00255","This study evaluates large language models (LLMs) in generating code from algorithm descriptions from recent NLP papers. The task requires two key competencies: (1) algorithm comprehension: synthesizing information from papers and academic literature to understand implementation logic, and (2) coding expertise: identifying dependencies and correctly implementing necessary APIs. To facilitate rigorous evaluation, we introduce SciReplicate-Bench, a benchmark of 100 tasks from 36 NLP papers published in 2024, featuring detailed annotations and comprehensive test cases. Building on SciReplicate-Bench, we propose Sci-Reproducer, a multi-agent framework consisting of a Paper Agent that interprets algorithmic concepts from literature and a Code Agent that retrieves dependencies from repositories and implement solutions. To assess algorithm understanding, we introduce reasoning graph accuracy, which quantifies similarity between generated and reference reasoning graphs derived from code comments and structure. For evaluating implementation quality, we employ execution accuracy, CodeBLEU, and repository dependency/API recall metrics. In our experiments, we evaluate various powerful Non-Reasoning LLMs and Reasoning LLMs as foundational models. The best-performing LLM using Sci-Reproducer achieves only 39% execution accuracy, highlighting the benchmark's difficulty.Our analysis identifies missing or inconsistent algorithm descriptions as key barriers to successful reproduction. We will open-source our benchmark, and code at https://github.com/xyzCS/SciReplicate-Bench.","2025-03-31","2025-05-22 20:02:37","2025-05-22 20:02:37","2025-05-22 20:02:29","","","","","","","SciReplicate-Bench","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2504.00255 [cs]","","/Users/ksoares/Zotero/storage/XIC7IJGG/Xiang et al. - 2025 - SciReplicate-Bench Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers.pdf; /Users/ksoares/Zotero/storage/I4D38J9D/2504.html","","","Computer Science - Computation and Language; Computer Science - Artificial Intelligence; Computer Science - Multiagent Systems; Computer Science - Software Engineering","","","","","","","","","","","","","","","","","","","arXiv:2504.00255","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X2ZMCZQG","preprint","2025","Witt, Christian Schroeder de","Open Challenges in Multi-Agent Security: Towards Secure Systems of Interacting AI Agents","","","","10.48550/arXiv.2505.02077","http://arxiv.org/abs/2505.02077","Decentralized AI agents will soon interact across internet platforms, creating security challenges beyond traditional cybersecurity and AI safety frameworks. Free-form protocols are essential for AI's task generalization but enable new threats like secret collusion and coordinated swarm attacks. Network effects can rapidly spread privacy breaches, disinformation, jailbreaks, and data poisoning, while multi-agent dispersion and stealth optimization help adversaries evade oversightcreating novel persistent threats at a systemic level. Despite their critical importance, these security challenges remain understudied, with research fragmented across disparate fields including AI security, multi-agent learning, complex systems, cybersecurity, game theory, distributed systems, and technical AI governance. We introduce \textbf{multi-agent security}, a new field dedicated to securing networks of decentralized AI agents against threats that emerge or amplify through their interactionswhether direct or indirect via shared environmentswith each other, humans, and institutions, and characterize fundamental security-performance trade-offs. Our preliminary work (1) taxonomizes the threat landscape arising from interacting AI agents, (2) surveys security-performance tradeoffs in decentralized AI systems, and (3) proposes a unified research agenda addressing open challenges in designing secure agent systems and interaction environments. By identifying these gaps, we aim to guide research in this critical area to unlock the socioeconomic potential of large-scale agent deployment on the internet, foster public trust, and mitigate national security risks in critical infrastructure and defense contexts.","2025-05-04","2025-05-22 20:02:37","2025-05-22 20:02:37","2025-05-22 20:02:31","","","","","","","Open Challenges in Multi-Agent Security","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2505.02077 [cs]","","/Users/ksoares/Zotero/storage/DJJZQQ8F/Witt - 2025 - Open Challenges in Multi-Agent Security Towards Secure Systems of Interacting AI Agents.pdf; /Users/ksoares/Zotero/storage/KFATZKCV/2505.html","","","Computer Science - Artificial Intelligence; Computer Science - Multiagent Systems; Computer Science - Cryptography and Security","","","","","","","","","","","","","","","","","","","arXiv:2505.02077","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BPQGDWLD","conferencePaper","2024","Liu, Zijun; Zhang, Yanzhe; Li, Peng; Liu, Yang; Yang, Diyi","A dynamic LLM-powered agent network for task-oriented agent collaboration","First Conference on Language Modeling","","","","https://openreview.net/forum?id=XII0Wp1XA9","Recent studies show that collaborating multiple large language model (LLM) powered agents is a promising way for task solving. However, current approaches are constrained by using a fixed number of agents and static communication structures. In this work, we propose automatically selecting a team of agents from candidates to collaborate in a dynamic communication structure toward different tasks and domains. Specifically, we build a framework named Dynamic LLM-Powered Agent Network (DyLAN) for LLM-powered agent collaboration, operating a two-stage paradigm: (1) Team Optimization and (2) Task Solving. During the first stage, we utilize an agent selection algorithm, based on an unsupervised metric called Agent Importance Score, enabling the selection of best agents according to their contributions in a preliminary trial, oriented to the given task. Then, in the second stage, the selected agents collaborate dynamically according to the query. Empirically, we demonstrate that DyLAN outperforms strong baselines in code generation, decision-making, general reasoning, and arithmetic reasoning tasks with moderate computational cost. On specific subjects in MMLU, selecting a team of agents in the team optimization stage improves accuracy by up to 25.0% in DyLAN.1","2024","2025-05-22 20:02:37","2025-05-26 13:19:13","2025-05-22 20:02:32","","","","","","","","","","","","","","","","","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/NU57E8GM/Liu et al. - 2024 - A dynamic LLM-powered agent network for task-oriented agent collaboration.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IHVW2ISW","preprint","2024","Lee, Cheryl; Xia, Chunqiu Steven; Yang, Longji; Huang, Jen-tse; Zhu, Zhouruixin; Zhang, Lingming; Lyu, Michael R.","A Unified Debugging Approach via LLM-Based Multi-Agent Synergy","","","","10.48550/arXiv.2404.17153","http://arxiv.org/abs/2404.17153","Software debugging is a time-consuming endeavor involving a series of steps, such as fault localization and patch generation, each requiring thorough analysis and a deep understanding of the underlying logic. While large language models (LLMs) demonstrate promising potential in coding tasks, their performance in debugging remains limited. Current LLM-based methods often focus on isolated steps and struggle with complex bugs. In this paper, we propose the first end-to-end framework, FixAgent, for unified debugging through multi-agent synergy. It mimics the entire cognitive processes of developers, with each agent specialized as a particular component of this process rather than mirroring the actions of an independent expert as in previous multi-agent systems. Agents are coordinated through a three-level design, following a cognitive model of debugging, allowing adaptive handling of bugs with varying complexities. Experiments on extensive benchmarks demonstrate that FixAgent significantly outperforms state-of-the-art repair methods, fixing 1.25$\times$ to 2.56$\times$ bugs on the repo-level benchmark, Defects4J. This performance is achieved without requiring ground-truth root-cause code statements, unlike the baselines. Our source code is available on https://github.com/AcceptePapier/UniDebugger.","2024-10-23","2025-05-22 20:02:37","2025-05-22 20:02:37","2025-05-22 20:02:33","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2404.17153 [cs]","","/Users/ksoares/Zotero/storage/GWAHHZ6D/Lee et al. - 2024 - A Unified Debugging Approach via LLM-Based Multi-Agent Synergy.pdf; /Users/ksoares/Zotero/storage/S942DS4Q/2404.html","","","Computer Science - Software Engineering","","","","","","","","","","","","","","","","","","","arXiv:2404.17153","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KRT78TFW","preprint","2025","Xu, Yisen; Lin, Feng; Yang, Jinqiu; Tse-Hsun; Chen; Tsantalis, Nikolaos","MANTRA: Enhancing Automated Method-Level Refactoring with Contextual RAG and Multi-Agent LLM Collaboration","","","","10.48550/arXiv.2503.14340","http://arxiv.org/abs/2503.14340","Maintaining and scaling software systems relies heavily on effective code refactoring, yet this process remains labor-intensive, requiring developers to carefully analyze existing codebases and prevent the introduction of new defects. Although recent advancements have leveraged Large Language Models (LLMs) to automate refactoring tasks, current solutions are constrained in scope and lack mechanisms to guarantee code compilability and successful test execution. In this work, we introduce MANTRA, a comprehensive LLM agent-based framework that automates method-level refactoring. MANTRA integrates Context-Aware Retrieval-Augmented Generation, coordinated Multi-Agent Collaboration, and Verbal Reinforcement Learning to emulate human decision-making during refactoring while preserving code correctness and readability. Our empirical study, conducted on 703 instances of ""pure refactorings"" (i.e., code changes exclusively involving structural improvements), drawn from 10 representative Java projects, covers the six most prevalent refactoring operations. Experimental results demonstrate that MANTRA substantially surpasses a baseline LLM model (RawGPT ), achieving an 82.8% success rate (582/703) in producing code that compiles and passes all tests, compared to just 8.7% (61/703) with RawGPT. Moreover, in comparison to IntelliJ's LLM-powered refactoring tool (EM-Assist), MANTRA exhibits a 50% improvement in generating Extract Method transformations. A usability study involving 37 professional developers further shows that refactorings performed by MANTRA are perceived to be as readable and reusable as human-written code, and in certain cases, even more favorable. These results highlight the practical advantages of MANTRA and emphasize the growing potential of LLM-based systems in advancing the automation of software refactoring tasks.","2025-03-27","2025-05-22 20:02:37","2025-05-22 20:02:37","2025-05-22 20:02:35","","","","","","","MANTRA","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2503.14340 [cs]","","/Users/ksoares/Zotero/storage/FN3BABY2/Xu et al. - 2025 - MANTRA Enhancing Automated Method-Level Refactoring with Contextual RAG and Multi-Agent LLM Collabo.pdf; /Users/ksoares/Zotero/storage/F7VCLNSY/2503.html","","","Computer Science - Software Engineering","","","","","","","","","","","","","","","","","","","arXiv:2503.14340","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TPJU6RRG","preprint","2025","Fan, Meihao; Fan, Ju; Tang, Nan; Cao, Lei; Li, Guoliang; Du, Xiaoyong","AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework","","","","10.48550/arXiv.2412.10422","http://arxiv.org/abs/2412.10422","Answering natural language (NL) questions about tables, known as Tabular Question Answering (TQA), is crucial because it allows users to quickly and efficiently extract meaningful insights from structured data, effectively bridging the gap between human language and machine-readable formats. Many of these tables are derived from web sources or real-world scenarios, which require meticulous data preparation (or data prep) to ensure accurate responses. However, preparing such tables for NL questions introduces new requirements that extend beyond traditional data preparation. This question-aware data preparation involves specific tasks such as column derivation and filtering tailored to particular questions, as well as question-aware value normalization or conversion, highlighting the need for a more nuanced approach in this context. Because each of the above tasks is unique, a single model (or agent) may not perform effectively across all scenarios. In this paper, we propose AutoPrep, a large language model (LLM)-based multi-agent framework that leverages the strengths of multiple agents, each specialized in a certain type of data prep, ensuring more accurate and contextually relevant responses. Given an NL question over a table, AutoPrep performs data prep through three key components. Planner: Determines a logical plan, outlining a sequence of high-level operations. Programmer: Translates this logical plan into a physical plan by generating the corresponding low-level code. Executor: Executes the generated code to process the table. To support this multi-agent framework, we design a novel Chain-of-Clauses reasoning mechanism for high-level operation suggestion, and a tool-augmented method for low-level code generation...","2025-05-02","2025-05-22 20:02:37","2025-05-22 20:02:37","2025-05-22 20:02:37","","","","","","","AutoPrep","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2412.10422 [cs]","","/Users/ksoares/Zotero/storage/C8KE42QK/Fan et al. - 2025 - AutoPrep Natural Language Question-Aware Data Preparation with a Multi-Agent Framework.pdf; /Users/ksoares/Zotero/storage/PSKZTIIR/2412.html","","","Computer Science - Computation and Language; Computer Science - Artificial Intelligence","","","","","","","","","","","","","","","","","","","arXiv:2412.10422","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z2PTKU29","preprint","2024","Yuan, Zhiqiang; Chen, Weitong; Wang, Hanlin; Yu, Kai; Peng, Xin; Lou, Yiling","TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation","","","","10.48550/arXiv.2409.19894","http://arxiv.org/abs/2409.19894","Code translation converts code from one programming language to another while maintaining its original functionality, which is crucial for software migration, system refactoring, and cross-platform development. Traditional rule-based methods rely on manually-written rules, which can be time-consuming and often result in less readable code. To overcome this, learning-based methods have been developed, leveraging parallel data to train models for automated code translation. More recently, the advance of Large Language Models (LLMs) further boosts learning-based code translation. Although promising, LLM-translated program still suffers from diverse quality issues (e.g., syntax errors and semantic errors). In particular, it can be challenging for LLMs to self-debug these errors when simply provided with the corresponding error messages. In this work, we propose a novel LLM-based multi-agent system TRANSAGENT, which enhances LLM-based code translation by fixing the syntax errors and semantic errors with the synergy between four LLM-based agents, including Initial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error Fixer. The main insight of TRANSAGENT is to first localize the error code block in the target program based on the execution alignment between the target and source program, which can narrow down the fixing space and thus lower down the fixing difficulties. To evaluate TRANSAGENT, we first construct a new benchmark from recent programming tasks to mitigate the potential data leakage issue. On our benchmark, TRANSAGENT outperforms the latest LLM-based code translation technique UniTrans in both translation effectiveness and efficiency; additionally, our evaluation on different LLMs show the generalization of TRANSAGENT and our ablation study shows the contribution of each agent.","2024-10-01","2025-05-22 20:04:37","2025-05-22 20:04:37","2025-05-22 20:03:57","","","","","","","TRANSAGENT","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2409.19894 [cs]","","/Users/ksoares/Zotero/storage/H6X9QT2M/Yuan et al. - 2024 - TRANSAGENT An LLM-Based Multi-Agent System for Code Translation.pdf; /Users/ksoares/Zotero/storage/EWZGEYD4/2409.html","","","Computer Science - Artificial Intelligence; Computer Science - Software Engineering","","","","","","","","","","","","","","","","","","","arXiv:2409.19894","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UA48UXRE","preprint","2024","Hu, Yue; Cai, Yuzhu; Du, Yaxin; Zhu, Xinyu; Liu, Xiangrui; Yu, Zijie; Hou, Yuchen; Tang, Shuo; Chen, Siheng","Self-Evolving Multi-Agent Collaboration Networks for Software Development","","","","10.48550/arXiv.2410.16946","http://arxiv.org/abs/2410.16946","LLM-driven multi-agent collaboration (MAC) systems have demonstrated impressive capabilities in automatic software development at the function level. However, their heavy reliance on human design limits their adaptability to the diverse demands of real-world software development. To address this limitation, we introduce EvoMAC, a novel self-evolving paradigm for MAC networks. Inspired by traditional neural network training, EvoMAC obtains text-based environmental feedback by verifying the MAC network's output against a target proxy and leverages a novel textual backpropagation to update the network. To extend coding capabilities beyond function-level tasks to more challenging software-level development, we further propose rSDE-Bench, a requirement-oriented software development benchmark, which features complex and diverse software requirements along with automatic evaluation of requirement correctness. Our experiments show that: i) The automatic requirement-aware evaluation in rSDE-Bench closely aligns with human evaluations, validating its reliability as a software-level coding benchmark. ii) EvoMAC outperforms previous SOTA methods on both the software-level rSDE-Bench and the function-level HumanEval benchmarks, reflecting its superior coding capabilities. The benchmark can be downloaded at https://yuzhu-cai.github.io/rSDE-Bench/.","2024-10-22","2025-05-22 20:04:37","2025-05-22 20:04:37","2025-05-22 20:03:58","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2410.16946 [cs]","","/Users/ksoares/Zotero/storage/HRX8PAEZ/Hu et al. - 2024 - Self-Evolving Multi-Agent Collaboration Networks for Software Development.pdf; /Users/ksoares/Zotero/storage/Y3ZBRCDD/2410.html","","","Computer Science - Artificial Intelligence; Computer Science - Multiagent Systems; Computer Science - Software Engineering","","","","","","","","","","","","","","","","","","","arXiv:2410.16946","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DGH894TN","conferencePaper","2024","Ramires, Rafael; Respício, Ana; Medeiros, Ibéria","KAVE: A Knowledge-Based Multi-Agent System for Web Vulnerability Detection","2024 IEEE International Conference on Web Services (ICWS)","","","","https://ieeexplore.ieee.org/abstract/document/10707503/","The growing use of the web has led to a rise in cyber attacks exploiting software vulnerabilities, thereby causing significant damage to companies and individuals. Static analysis tools can assist programmers in identifying vulnerabilities within their code. However, these tools are prone to producing false positives and lack precision, which relegates them to a somewhat marginalised role in software development. This paper proposes a new and more effective static analysis approach for assessing and evaluating web applications against vulnerabilities by using a knowledge-based multi-agent system web vulnerability detector called KAVE. The multi-agent system performs static taint analysis over a specially designed multi-layer knowledge graph, whereas this graph aggregates diverse interconnected representations of the lexical and semantic features of the application’s source code, their data and control flows, and function calls. Additionally, this graph integrates security properties associated with vulnerabilities. The evaluation results of KAVE and comparison with existing tools showed that KAVE employs an effective and efficient method to detect vulnerabilities in web applications, finding 235 vulnerabilities with a precision of 95.9% over 12 open-source PHP web applications.","2024","2025-05-22 20:04:37","2025-05-26 13:25:17","2025-05-22 20:04:00","489–500","","","","","","KAVE","","","","","IEEE","","","","","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/5IQEZ48X/Ramires et al. - 2024 - KAVE A Knowledge-Based Multi-Agent System for Web Vulnerability Detection.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SK4PELH2","preprint","2025","Chun, Jina; Chen, Qihong; Li, Jiawei; Ahmed, Iftekhar","Is Multi-Agent Debate (MAD) the Silver Bullet? An Empirical Analysis of MAD in Code Summarization and Translation","","","","10.48550/arXiv.2503.12029","http://arxiv.org/abs/2503.12029","Large Language Models (LLMs) have advanced autonomous agents' planning and decision-making, yet they struggle with complex tasks requiring diverse expertise and multi-step reasoning. Multi-Agent Debate (MAD) systems, introduced in NLP research, address this gap by enabling structured debates among LLM-based agents to refine solutions iteratively. MAD promotes divergent thinking through role-specific agents, dynamic interactions, and structured decision-making. Recognizing parallels between Software Engineering (SE) and collaborative human problem-solving, this study investigates MAD's effectiveness on two SE tasks. We adapt MAD systems from NLP, analyze agent interactions to assess consensus-building and iterative refinement, and propose two enhancements targeting observed weaknesses. Our findings show that structured debate and collaboration improve problem-solving and yield strong performance in some cases, highlighting MAD's potential for SE automation while identifying areas for exploration.","2025-03-15","2025-05-22 20:04:37","2025-05-22 20:04:37","2025-05-22 20:04:04","","","","","","","Is Multi-Agent Debate (MAD) the Silver Bullet?","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2503.12029 [cs]","","/Users/ksoares/Zotero/storage/326RLCQK/Chun et al. - 2025 - Is Multi-Agent Debate (MAD) the Silver Bullet An Empirical Analysis of MAD in Code Summarization an.pdf; /Users/ksoares/Zotero/storage/V8M7L5H6/2503.html","","","Computer Science - Software Engineering","","","","","","","","","","","","","","","","","","","arXiv:2503.12029","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XNX2WYBK","thesis","2025","Eichhorn, Tim","CLAIR: Generating On-Demand Low-Code Application Documentation through Knowledge Graph and LLM-based Multi-Agent System Integration","","","","","http://essay.utwente.nl/106037/","Low-Code has revolutionised software development by enabling rapid application creation with minimal coding effort. However, as Low-Code applications scale, challenges related to documentation, maintainability, and technical debt become increasingly prevalent. Inadequate documentation impedes collaboration, maintenance, troubleshooting, and knowledge retention, particularly in agile development environments where documentation is often disregarded. This thesis introduces CLAIR (Connecting Low-Code and Artificial Intelligence for RAG), an AI-driven documentation assistant that leverages a knowledge graph and a LLM-based Multi Agent System to generate on-demand, context-aware documentation for Low-Code applications. The tool is validated using the Mendix platform, and the study employs a Design Science Methodology to design, develop, and validate the proposed solution.  A comprehensive literature review explores challenges in Low-Code documentation, emphasising issues such as fragmented knowledge, poor traceability, and the impact of missing documentation. A survey and case study at CAPE Groep, an Low-Code consultancy firm, further highlight the documentation needs of Low-Code developers and business analysts. To address these issues, CLAIR integrates knowledge graphs to structure and store LowCode application data, enabling efficient querying and multi-hop reasoning. Additionally, a Multi-Agent LLM System dynamically generates and enhances documentation based on application data and user queries.  CLAIR automates documentation generation across various phases of the Low-Code Development Lifecycle, including the design, development, and maintenance phases. Key features include automated extraction of domain models, microflows, and dependencies, generation of high-level summaries and technical details, and support for troubleshooting. The system enhances maintainability, knowledge retention, and team collaboration by ensuring up-to-date, structured, and queryable on-demand documentation.  Validation was conducted through expert evaluations and a series of test cases using Technical Action Research, demonstrating CLAIR’s ability to generate accurate, usable, and context-aware documentation. Findings indicate that automated documentation significantly reduces the time and effort needed to create high-quality documentation. This documentation leads to reduced cognitive load, technical debt, and maintenance effort, making it a valuable asset for Low-Code development teams.  This research contributes to the fields of Low-Code development, automated documentation, and AI-driven knowledge management, proposing an innovative approach that combines knowledge graphs and LLMs to enhance documentation processes. By bridging the gap between Low-Code application development and AI-driven automation, CLAIR sets a foundation for future advancements in intelligent Low-Code documentation and maintainability solutions.","2025","2025-05-22 20:04:37","2025-05-26 13:21:38","2025-05-22 20:04:04","","","","","","","CLAIR","","","","","University of Twente","","","","Master's Thesis","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/VUDV8ZXX/Eichhorn - 2025 - CLAIR Generating On-Demand Low-Code Application Documentation through Knowledge Graph and LLM-based.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3UCPU7H7","preprint","2025","Ma, Jenny; Sahni, Riya; Sreedhar, Karthik; Chilton, Lydia B.","AgentDynEx: Nudging the Mechanics and Dynamics of Multi-Agent Simulations","","","","10.48550/arXiv.2504.09662","http://arxiv.org/abs/2504.09662","Multi-agent large language model simulations have the potential to model complex human behaviors and interactions. If the mechanics are set up properly, unanticipated and valuable social dynamics can surface. However, it is challenging to consistently enforce simulation mechanics while still allowing for notable and emergent dynamics. We present AgentDynEx, an AI system that helps set up simulations from user-specified mechanics and dynamics. AgentDynEx uses LLMs to guide users through a Configuration Matrix to identify core mechanics and define milestones to track dynamics. It also introduces a method called \textit{nudging}, where the system dynamically reflects on simulation progress and gently intervenes if it begins to deviate from intended outcomes. A technical evaluation found that nudging enables simulations to have more complex mechanics and maintain its notable dynamics compared to simulations without nudging. We discuss the importance of nudging as a technique for balancing mechanics and dynamics of multi-agent simulations.","2025-04-13","2025-05-22 20:04:37","2025-05-22 20:04:37","2025-05-22 20:04:06","","","","","","","AgentDynEx","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2504.09662 [cs]","","/Users/ksoares/Zotero/storage/GS5D6NAV/Ma et al. - 2025 - AgentDynEx Nudging the Mechanics and Dynamics of Multi-Agent Simulations.pdf; /Users/ksoares/Zotero/storage/LIECZX4Q/2504.html","","","Computer Science - Artificial Intelligence; Computer Science - Multiagent Systems; Computer Science - Human-Computer Interaction","","","","","","","","","","","","","","","","","","","arXiv:2504.09662","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8XDHFIJY","conferencePaper","2025","Gorkavyy, M. A.; Voroshchenko, V. D.; Gorkavyy, A. I.","Development of RL DDPG Agent for Planning Energy-Efficient Trajectory of Collaborative Robot","2025 International Russian Smart Industry Conference (SmartIndustryCon)","","","","https://ieeexplore.ieee.org/abstract/document/10986035/","In the global scientific community, there are already approaches to optimizing robot trajectories based on classical mathematical methods. These methods often require significant computational resources, especially when solving high-dimensional problems in real time. In this regard, the use of approximate solutions, such as neural networks and reinforcement learning methods, is becoming a promising direction. In this paper, we train the Reinforcement Learning Deep Deterministic Policy Gradient method for creating an agent for optimizing robot trajectories based on the energy consumption criterion. The agent demonstrated the ability to plan trajectories with minimal energy consumption, with an error of no more than 1.3%. This proves the effectiveness of the trained method and its applicability in real production conditions.","2025","2025-05-22 20:04:37","2025-05-26 13:23:29","2025-05-22 20:04:06","472–476","","","","","","","","","","","IEEE","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DVFNVQ99","preprint","2025","Liang, Jenny T.; Kumar, Aayush; Bajpai, Yasharth; Gulwani, Sumit; Le, Vu; Parnin, Chris; Radhakrishna, Arjun; Tiwari, Ashish; Murphy-Hill, Emerson; Soares, Guastavo","TableTalk: Scaffolding Spreadsheet Development with a Language Agent","","","","10.48550/arXiv.2502.09787","http://arxiv.org/abs/2502.09787","Despite its ubiquity in the workforce, spreadsheet programming remains challenging as programmers need both spreadsheet-specific knowledge (e.g., APIs to write formulas) and problem-solving skills to create complex spreadsheets. Large language models (LLMs) can help automate aspects of this process, and recent advances in planning and reasoning have enabled language agents, which dynamically plan, use tools, and take iterative actions to complete complex tasks. These agents observe, plan, and act, making them well-suited to scaffold spreadsheet programming by following expert processes. We present TableTalk, a language agent that helps programmers build spreadsheets conversationally. Its design reifies three design principles -- scaffolding, flexibility, and incrementality -- which we derived from two studies of seven programmers and 62 Excel templates. TableTalk structures spreadsheet development by generating step-by-step plans and suggesting three next steps users can choose from. It also integrates tools that enable incremental spreadsheet construction. A user study with 20 programmers shows that TableTalk produces spreadsheets 2.3 times more likely to be preferred over a baseline agent, while reducing cognitive load and time spent reasoning about spreadsheet actions by 12.6%. TableTalk's approach has implications for human-agent collaboration. This includes providing persistent direct manipulation interfaces for stopping or undoing agent actions, while ensuring that such interfaces for accepting actions can be deactivated.","2025-02-13","2025-05-22 20:04:37","2025-05-22 20:04:37","2025-05-22 20:04:08","","","","","","","TableTalk","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2502.09787 [cs]","","/Users/ksoares/Zotero/storage/NPLQIY92/Liang et al. - 2025 - TableTalk Scaffolding Spreadsheet Development with a Language Agent.pdf; /Users/ksoares/Zotero/storage/37BJY9RT/2502.html","","","Computer Science - Artificial Intelligence; Computer Science - Software Engineering; Computer Science - Human-Computer Interaction","","","","","","","","","","","","","","","","","","","arXiv:2502.09787","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JGAU9WPR","preprint","2025","Ju, Tianjie; Wang, Bowen; Fei, Hao; Lee, Mong-Li; Hsu, Wynne; Li, Yun; Wang, Qianren; Cheng, Pengzhou; Wu, Zongru; Zhang, Zhuosheng; Liu, Gongshen","Investigating the Adaptive Robustness with Knowledge Conflicts in LLM-based Multi-Agent Systems","","","","10.48550/arXiv.2502.15153","http://arxiv.org/abs/2502.15153","Recent advances in Large Language Models (LLMs) have upgraded them from sophisticated text generators to autonomous agents capable of corporation and tool use in multi-agent systems (MASs). However, the robustness of these LLM-based MASs, especially under knowledge conflicts, remains unclear. In this paper, we design four comprehensive metrics to investigate the robustness of MASs when facing mild or task-critical knowledge conflicts. We first analyze mild knowledge conflicts introduced by heterogeneous agents and find that they do not harm system robustness but instead improve collaborative decision-making. Next, we investigate task-critical knowledge conflicts by synthesizing knowledge conflicts and embedding them into one of the agents. Our results show that these conflicts have surprisingly little to no impact on MAS robustness. Furthermore, we observe that MASs demonstrate certain self-repairing capabilities by reducing their reliance on knowledge conflicts and adopting alternative solution paths to maintain stability. Finally, we conduct ablation studies on the knowledge conflict number, agent number, and interaction rounds, finding that the self-repairing capability of MASs has intrinsic limits, and all findings hold consistently across various factors. Our code is publicly available at https://github.com/wbw625/MultiAgentRobustness.","2025-02-21","2025-05-22 20:04:37","2025-05-22 20:04:37","2025-05-22 20:04:10","","","","","","","","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2502.15153 [cs]","","/Users/ksoares/Zotero/storage/WANGKQTU/Ju et al. - 2025 - Investigating the Adaptive Robustness with Knowledge Conflicts in LLM-based Multi-Agent Systems.pdf; /Users/ksoares/Zotero/storage/73XEYPIP/2502.html","","","Computer Science - Computation and Language","","","","","","","","","","","","","","","","","","","arXiv:2502.15153","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VTJYXMU8","preprint","2025","Yu, Zhongming; Zhang, Hejia; Zhao, Yujie; Huang, Hanxian; Yao, Matrix; Ding, Ke; Zhao, Jishen","OrcaLoca: An LLM Agent Framework for Software Issue Localization","","","","10.48550/arXiv.2502.00350","http://arxiv.org/abs/2502.00350","Recent developments in Large Language Model (LLM) agents are revolutionizing Autonomous Software Engineering (ASE), enabling automated coding, problem fixes, and feature improvements. However, localization -- precisely identifying software problems by navigating to relevant code sections -- remains a significant challenge. Current approaches often yield suboptimal results due to a lack of effective integration between LLM agents and precise code search mechanisms. This paper introduces OrcaLoca, an LLM agent framework that improves accuracy for software issue localization by integrating priority-based scheduling for LLM-guided action, action decomposition with relevance scoring, and distance-aware context pruning. Experimental results demonstrate that OrcaLoca becomes the new open-source state-of-the-art (SOTA) in function match rate (65.33%) on SWE-bench Lite. It also improves the final resolved rate of an open-source framework by 6.33 percentage points through its patch generation integration.","2025-02-01","2025-05-22 20:04:37","2025-05-22 20:04:37","2025-05-22 20:04:12","","","","","","","OrcaLoca","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2502.00350 [cs]","","/Users/ksoares/Zotero/storage/87USUCLZ/Yu et al. - 2025 - OrcaLoca An LLM Agent Framework for Software Issue Localization.pdf; /Users/ksoares/Zotero/storage/UZ993KW4/2502.html","","","Computer Science - Artificial Intelligence; Computer Science - Software Engineering","","","","","","","","","","","","","","","","","","","arXiv:2502.00350","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2RGC3L2X","preprint","2025","Wang, Xinchen; Gao, Pengfei; Peng, Chao; Hu, Ruida; Gao, Cuiyun","CodeVisionary: An Agent-based Framework for Evaluating Large Language Models in Code Generation","","","","10.48550/arXiv.2504.13472","http://arxiv.org/abs/2504.13472","Large language models (LLMs) have demonstrated strong capabilities in code generation, underscoring the critical need for rigorous and comprehensive evaluation. Existing evaluation approaches fall into three categories, including human-centered, metric-based, and LLM-based. Considering that human-centered approaches are labour-intensive and metric-based ones overly rely on reference answers, LLM-based approaches are gaining increasing attention due to their stronger contextual understanding capabilities and superior efficiency. However, the performance of LLM-based approaches remains limited due to: (1) lack of multisource domain knowledge, and (2) insufficient comprehension of complex code. To mitigate the limitations, we propose CodeVisionary, the first LLM-based agent framework for evaluating LLMs in code generation. CodeVisionary consists of two stages: (1) Multiscore knowledge analysis stage, which aims to gather multisource and comprehensive domain knowledge by formulating and executing a stepwise evaluation plan. (2) Negotiation-based scoring stage, which involves multiple judges engaging in discussions to better comprehend the complex code and reach a consensus on the evaluation score. Extensive experiments demonstrate that CodeVisionary achieves the best performance for evaluating LLMs in code generation, outperforming the best baseline methods with average improvements of 0.202, 0.139, and 0.117 in Pearson, Spearman, and Kendall-Tau coefficients, respectively. Besides, CodeVisionary provides detailed evaluation reports, which assist developers in identifying shortcomings and making improvements. The resources of CodeVisionary are available at https://anonymous.4open.science/r/CodeVisionary.","2025-04-18","2025-05-22 20:04:37","2025-05-22 20:04:37","2025-05-22 20:04:14","","","","","","","CodeVisionary","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2504.13472 [cs]","","/Users/ksoares/Zotero/storage/V4PH75XI/Wang et al. - 2025 - CodeVisionary An Agent-based Framework for Evaluating Large Language Models in Code Generation.pdf; /Users/ksoares/Zotero/storage/4KJ9MGQB/2504.html","","","Computer Science - Computation and Language; Computer Science - Artificial Intelligence; Computer Science - Software Engineering; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2504.13472","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PQRXSWCN","preprint","2025","Zhu, Yueheng; Liu, Chao; He, Xuan; Ren, Xiaoxue; Liu, Zhongxin; Pan, Ruwei; Zhang, Hongyu","AdaCoder: An Adaptive Planning and Multi-Agent Framework for Function-Level Code Generation","","","","10.48550/arXiv.2504.04220","http://arxiv.org/abs/2504.04220","Recently, researchers have proposed many multi-agent frameworks for function-level code generation, which aim to improve software development productivity by automatically generating function-level source code based on task descriptions. A typical multi-agent framework consists of Large Language Model (LLM)-based agents that are responsible for task planning, code generation, testing, debugging, etc. Studies have shown that existing multi-agent code generation frameworks perform well on ChatGPT. However, their generalizability across other foundation LLMs remains unexplored systematically. In this paper, we report an empirical study on the generalizability of four state-of-the-art multi-agent code generation frameworks across six open-source LLMs with varying parameter sizes, architectures, and performance levels. Our study reveals the unstable generalizability of existing frameworks on diverse foundation LLMs. Based on the findings obtained from the empirical study, we propose AdaCoder, a novel adaptive planning, multi-agent framework for function-level code generation. AdaCoder has two phases. Phase-1 is an initial code generation step without planning, which uses an LLM-based coding agent and a script-based testing agent to unleash LLM's native power, identify cases beyond LLM's power, and determine the errors hindering execution. Phase-2 adds a rule-based debugging agent and an LLM-based planning agent for iterative code generation with planning. Our evaluation shows that AdaCoder achieves higher generalizability on diverse LLMs. Compared to the best baseline MapCoder, AdaCoder is on average 27.69% higher in Pass@1, 16 times faster in inference, and 12 times lower in token consumption.","2025-04-05","2025-05-22 20:04:37","2025-05-22 20:04:37","2025-05-22 20:04:18","","","","","","","AdaCoder","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2504.04220 [cs]","","/Users/ksoares/Zotero/storage/N7M9FE5E/Zhu et al. - 2025 - AdaCoder An Adaptive Planning and Multi-Agent Framework for Function-Level Code Generation.pdf; /Users/ksoares/Zotero/storage/3FVN8AS6/2504.html","","","Computer Science - Software Engineering","","","","","","","","","","","","","","","","","","","arXiv:2504.04220","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3EE3BKWD","preprint","2025","Islam, Md Ashraful; Ali, Mohammed Eunus; Parvez, Md Rizwan","CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging","","","","10.48550/arXiv.2502.05664","http://arxiv.org/abs/2502.05664","Large Language Models (LLMs) have made significant strides in code generation and problem solving. Current approaches employ external tool-based iterative debuggers that use compiler or other tool-based runtime feedback to refine coarse programs generated by various methods. However, the effectiveness of these approaches heavily relies on the quality of the initial code generation, which remains an open challenge. In this paper, we introduce CodeSim, a novel multi-agent code generation framework that comprehensively addresses the stages of program synthesis-planning, coding, and debugging-through a human-like perception approach. As human verifies their understanding of any algorithms through visual simulation, CodeSim uniquely features a method of plan verification and internal debugging through the step-by-step simulation of input/output. Extensive experiments across seven challenging competitive problem-solving and program synthesis benchmarks demonstrate CodeSim's remarkable code generation capabilities. Our framework achieves new state-of-the-art (pass@1) results-(HumanEval 95.1%, MBPP 90.7%, APPS 22%, and CodeContests 29.1%). Furthermore, our method shows potential for even greater enhancement when cascaded with external debuggers. To facilitate further research and development in this area, we have open-sourced our framework in this link (https://kagnlp.github.io/codesim.github.io/).","2025-02-08","2025-05-22 20:04:37","2025-05-22 20:04:37","2025-05-22 20:04:20","","","","","","","CODESIM","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2502.05664 [cs]","","/Users/ksoares/Zotero/storage/MRNMT795/Islam et al. - 2025 - CODESIM Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debu.pdf; /Users/ksoares/Zotero/storage/8A74MZFP/2502.html","","","Computer Science - Computation and Language; Computer Science - Artificial Intelligence","","","","","","","","","","","","","","","","","","","arXiv:2502.05664","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B4N4DVNU","journalArticle","2025","Vella, S.; Hussain, F.; Sharieh, S.; Ferworn, A.","ContentCreator: Programming AI Agent Workflows","Automation, Robotics & Communications for Industry 4.0/5.0","","","","https://www.researchgate.net/profile/Sergey-Yurish/publication/389563762_ARCI_2025_Conference_Proceedings/links/67c829b3cc055043ce6dd5ac/ARCI-2025-Conference-Proceedings.pdf#page=162","AI (Artificial Intelligence) agents are increasingly used to automate routine office work, such as summarizing and understanding documents. This research presents a novel domain-specific programming language, ContentCreator (CC), for the creation of personas and execution of workflows. We show how LLMs can translate procedures in natural language into the CC language. An interpreter has been built to run the CC language programs. The initial programming of computers started with individual calls to assembly language instructions. In the same way, today’s LLM applications are built with many individual calls to LLMs. CC provides an abstraction for creating applications that automate content creation workflows, with easy-to-create agent personas and easy-to-code document passing between agents. Domain-specific languages like ContentCreator can make AI agent programming accessible to anyone, regardless of programming knowledge.","2025","2025-05-22 20:04:37","2025-05-26 13:22:27","2025-05-22 20:04:21","161","","","","","","ContentCreator","","","","","","","","","","","","Google Scholar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"26YIJTKM","preprint","2025","Seo, Wonduk; Lee, Juhyeon; Bu, Yi","SPIO: Ensemble and Selective Strategies via LLM-Based Multi-Agent Planning in Automated Data Science","","","","10.48550/arXiv.2503.23314","http://arxiv.org/abs/2503.23314","Large Language Models (LLMs) have revolutionized automated data analytics and machine learning by enabling dynamic reasoning and adaptability. While recent approaches have advanced multi-stage pipelines through multi-agent systems, they typically rely on rigid, single-path workflows that limit the exploration and integration of diverse strategies, often resulting in suboptimal predictions. To address these challenges, we propose SPIO (Sequential Plan Integration and Optimization), a novel framework that leverages LLM-driven decision-making to orchestrate multi-agent planning across four key modules: data preprocessing, feature engineering, modeling, and hyperparameter tuning. In each module, dedicated planning agents independently generate candidate strategies that cascade into subsequent stages, fostering comprehensive exploration. A plan optimization agent refines these strategies by suggesting several optimized plans. We further introduce two variants: SPIO-S, which selects a single best solution path as determined by the LLM, and SPIO-E, which selects the top k candidate plans and ensembles them to maximize predictive performance. Extensive experiments on Kaggle and OpenML datasets demonstrate that SPIO significantly outperforms state-of-the-art methods, providing a robust and scalable solution for automated data science task.","2025-03-30","2025-05-22 20:04:37","2025-05-22 20:04:37","2025-05-22 20:04:24","","","","","","","SPIO","","","","","arXiv","","","","","","","arXiv.org","","arXiv:2503.23314 [cs]","","/Users/ksoares/Zotero/storage/UDYSFH4B/Seo et al. - 2025 - SPIO Ensemble and Selective Strategies via LLM-Based Multi-Agent Planning in Automated Data Science.pdf; /Users/ksoares/Zotero/storage/CGGWWDBS/2503.html","","","Computer Science - Computation and Language; Computer Science - Artificial Intelligence; Computer Science - Multiagent Systems; Computer Science - Machine Learning","","","","","","","","","","","","","","","","","","","arXiv:2503.23314","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3GVI68TG","document","2025","Berlin, Claudia","Exploring an AI Agentic Workflow for Solving Challenging Coding Problems: An Evaluation of a Large Language Model Based Multi-Agent System","","","","","https://www.diva-portal.org/smash/record.jsf?pid=diva2:1949004","Generative Artificial Intelligence (Gen AI) models have become very popular, especially after the public release of ChatGPT in late 2022. The demonstrated capabilities of these models have led researchers to use them to build agentic workflows, including Multi-Agent Systems (MAS), and explore their potential. Previous studies that investigate these systems’ coding abilities have shown promising results. However, these studies have mainly used coding benchmarks consisting of simple coding problems, leaving a gap in understanding coding ability of agentic workflows when facing coding problems of greater difficulty. This study tries to fill this gap by developing a MAS and evaluating its coding ability against 120 selected coding problems taken from Kattis, with the difficulty levels ranging from easy to hard. In the experiment, both the developed MAS (configured with Llama 3-70b) and a single Large Language Model (LLM) (Llama 3-70b) were tested on the selected coding problems using Kattis’ assessment system. The experiment showed that the MAS was significantly better than the single LLM when zero- shot prompting was used, increasing acceptance rates by 6.7% and decreasing failure rates by 11.7%. Overall, the results of this study suggest that using a designed LLM-based MAS offers a significant performance boost compared to a single LLM.","2025","2025-05-22 20:04:37","2025-05-26 13:24:16","2025-05-22 20:04:27","","","","","","","Exploring an AI Agentic Workflow for Solving Challenging Coding Problems","","","","","","","","","","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/JHX9L45V/Berlin - 2025 - Exploring an AI Agentic Workflow for Solving Challenging Coding Problems An Evaluation of a Large L.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L2CDPYSE","journalArticle","2025","He, Junda; Treude, Christoph; Lo, David","LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead","ACM Transactions on Software Engineering and Methodology","","1049-331X, 1557-7392","10.1145/3712003","https://dl.acm.org/doi/10.1145/3712003","Integrating Large Language Models (LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities that are competitive with human planning and reasoning. This paper explores the transformative potential of integrating Large Language Models into Multi-Agent (LMA) systems for addressing complex challenges in software engineering (SE). By leveraging the collaborative and specialized abilities of multiple agents, LMA systems enable autonomous problem-solving, improve robustness, and provide scalable solutions for managing the complexity of real-world software projects. In this paper, we conduct a systematic review of recent primary studies to map the current landscape of LMA applications across various stages of the software development lifecycle (SDLC). To illustrate current capabilities and limitations, we perform two case studies to demonstrate the effectiveness of state-of-the-art LMA frameworks. Additionally, we identify critical research gaps and propose a comprehensive research agenda focused on enhancing individual agent capabilities and optimizing agent synergy. Our work outlines a forward-looking vision for developing fully autonomous, scalable, and trustworthy LMA systems, laying the foundation for the evolution of Software Engineering 2.0.","2025-01-13","2025-05-22 20:04:37","2025-05-22 20:04:37","2025-05-22 20:04:27","3712003","","","","","ACM Trans. Softw. Eng. Methodol.","LLM-Based Multi-Agent Systems for Software Engineering","","","","","","","en","","","","","DOI.org (Crossref)","","","","/Users/ksoares/Zotero/storage/JA3WIXV9/He et al. - 2025 - LLM-Based Multi-Agent Systems for Software Engineering Literature Review, Vision and the Road Ahead.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5YEBKMVG","journalArticle","2024","Hsih, Mei-Hua; Yang, Jian-Xin; Hsieh, Chen-Chiung","Design and Implementation of an Intelligent Web Service Agent Based on Seq2Seq and Website Crawler","Information","","","","https://www.mdpi.com/2078-2489/15/12/818","This paper proposes using a web crawler to organize website content as a dialogue tree in some domains. We build an intelligent customer service agent based on this dialogue tree for general usage. The encoder-decoder architecture Seq2Seq is used to understand natural language and then modified as a bi-directional LSTM to increase the accuracy of the polysemy cases. The attention mechanism is added in the decoder to improve the problem of accuracy decreasing as the sentence grows in length. We conducted four experiments. The first is an ablation experiment demonstrating that the Seq2Seq + Bi-directional LSTM + Attention mechanism is superior to LSTM, Seq2Seq, Seq2Seq + Attention mechanism in natural language processing. Using an open-source Chinese corpus for testing, the accuracy was 82.1%, 63.4%, 69.2%, and 76.1%, respectively. The second experiment uses knowledge of the target domain to ask questions. Five thousand data from Taiwan Water Supply Company were used as the target training data, and a thousand questions that differed from the training data but related to water were used for testing. The accuracy of RasaNLU and this study were 86.4% and 87.1%, respectively. The third experiment uses knowledge from non-target domains to ask questions and compares answers from RasaNLU with the proposed neural network model. Five thousand questions were extracted as the training data, including chat databases from eight public sources such as Weibo, Tieba, Douban, and other well-known social networking sites in mainland China and PTT in Taiwan. Then, 1000 questions from the same corpus that differed from the training data for testing were extracted. The accuracy of this study was 83.2%, which is far better than RasaNLU. It is confirmed that the proposed model is more accurate in the general field. The last experiment compares this study with voice assistants like Xiao Ai, Google Assistant, Siri, and Samsung Bixby. Although this study cannot answer vague questions accurately, it is more accurate in the trained application fields.","2024","2025-05-22 20:04:37","2025-05-26 13:23:02","2025-05-22 20:04:33","818","","12","15","","","","","","","","","","","","","","","Google Scholar","","Publisher: MDPI","","/Users/ksoares/Zotero/storage/FT3U5VVK/818.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WFRZ7QIS","journalArticle","","Wen, Zixin; Cai, Yifu; Lee, Kyle; Estep, Sam; Sunshine, Joshua; Singh, Aarti; Chi, Yuejie; Ni, Wode","Feynman: Knowledge-Infused Diagramming Agent for Scaling Visual Reasoning Data","","","","","https://openreview.net/forum?id=jNmsuEE4Gf","Visual reasoning is an essential ability of state-of-the-art multi-modal AI systems. Improving these systems requires high-quality vision-language data at scale. Despite the abundance of internet image and text data, knowledge-rich and well-aligned image-text pairs are rare. In this paper, we present a scalable data generation pipeline built with our diagramming agent, Feynman. To create diagrams, Feynman first enumerates domain-specific knowledge components (""ideas"") and performs code planning based on the ideas. Given the plan, Feynman translates ideas into simple declarative programs and iterates to receives feedback and visually refine diagrams. Finally, the declarative programs are rendered by the Penrose diagramming system. The optimization-based rendering of Penrose preserves the visual semantics while injecting fresh randomness into the layout, thereby producing diagrams with visual consistency and diversity. As a result, Feynman can author diagrams along with grounded captions with very little cost and time. Using Feynman, we synthesized a dataset with more than 100  well-aligned diagram-caption pairs. We also curate a visual-language benchmark, Diagramma, from freshly generated data.","","2025-05-22 20:04:37","2025-05-26 13:24:30","2025-05-22 20:04:35","","","","","","","Feynman","","","","","","","","","","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/KVZMW22A/Wen et al. - Feynman Knowledge-Infused Diagramming Agent for Scaling Visual Reasoning Data.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SYXEVSUA","thesis","2024","Mendoza Juan, Yago","Development of a multi-agent, LLM-driven system to enhance human-machine interaction: integrating DSPy with modular agentic strategies and logical reasoning layers for the autonomous generation of smart contracts","","","","","https://upcommons.upc.edu/handle/2117/414255","Recent advances in hardware capabilities have significantly accelerated the development of neural networks, leading to the emergence of Large Language Models (LLMs). Originally designed for text generation, these models have evolved to perform an increasingly broad spectrum of tasks, demonstrating capabilities that extend beyond early predictions based on their sole auto-regressive nature. During my internship at Sony’s R&D Center Brussels Laboratory, I studied the relevance of these models for inclusion in a broader project focused on fan engagement in Web3, integral to the Loyalty 3.0 initiative, operating on the Ethereum Virtual Machine (EVM) to streamline the deployment of decentralized protocols. The module developed in this thesis autonomously generates these protocols by interpreting natural language inputs from non-expert users, showcasing state-of-the-art language models’ capabilities in translating early propositions into advanced source code. The system incorporates a Human-Machine Interaction Module, syntax generation with specialized layers, and a novel Survey Augmented Generation for Validation (SuAV) technique for alignment assessment. This system integrates DSPy for declarative syntax prompting, custom modular strategies for enhanced flexibility, and LangChain sequence patterns to ensure robust and accurate protocol generation. A comprehensive study comparing various techniques revealed the effectiveness of a hybrid model with conversational agents, particularly for smaller language models. Yet, the research highlights the complexities of optimizing LLMs for specialized tasks, emphasizing the need for nuanced approaches that balance model capabilities with task-specific requirements. To gain a comprehensive understanding of the overall implications and contextual relevance of the material presented in this work, it is advisable to prioritize reading the conclusions, followed by the epilogue. These sections provide valuable insights beyond the numerical results of the thesis, offering a broader perspective on the study’s significance and impact.","2024","2025-05-22 20:04:37","2025-05-26 13:23:23","2025-05-22 20:04:37","","","","","","","Development of a multi-agent, LLM-driven system to enhance human-machine interaction","","","","","Universitat Politècnica de Catalunya","","","","Master's Thesis","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/ZI9BQZRK/Mendoza Juan - 2024 - Development of a multi-agent, LLM-driven system to enhance human-machine interaction integrating DS.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZLRG5Q7S","journalArticle","","Zheng, Yi; Huang, Haibin; Ma, Chongyang; Wang, Luozhou; Shi, Kanle; Chen, Ying-Cong; Wan, Pengfei; ZHANG, Di","Explicit-Constrained Single Agent for Enhanced Task-Solving in LLMs","","","","","https://openreview.net/forum?id=GO4Sd6LUuY","In this study, we introduce the Explicitly Constrained Agent (EC-Agent), a novel approach designed to enhance the task-solving capabilities of Large Language Models (LLMs). Unlike existing multi-agent systems that depend on agents evaluating tasks from different perspectives, EC-Agent explicitly imposes task-oriented constraints for LLMs. Our observations are two-fold: first, assigning agents to sub-tasks with defined responsibilities implicitly sets constraints; second, these multi-agent systems often struggle with accurately assigning agents to sub-tasks, leading to overlapping duties and potential misguidance. In contrast, our single-agent system, driven by explicit methods and constraints, provides LLMs with detailed prompts, resulting in more precise responses. EC-Agent consists of two stages: a Reasoning Stage and a Summary Stage. 1) In the Reasoning Stage, three modules are proposed: Explicit Method, Explicit Constraint, and Execution. Specifically, LLMs utilize the Explicit Method and Constraint modules to analyze the task type and specific rules, generating multiple suitable methods and constraints. Subsequently, the Execution module combines these methods and constraints to produce and output possible solutions. 2) In the Summary Stage, LLMs evaluate the multiple reasoning processes and results from the previous step. They rectify any inconsistencies, summarize the information, and output the final result. Experimental results demonstrate that EC-Agent outperforms previous methods across a variety of tasks.","","2025-05-22 20:04:59","2025-05-26 13:24:04","2025-05-22 20:04:55","","","","","","","","","","","","","","","","","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/QLVBVMFK/Zheng et al. - Explicit-Constrained Single Agent for Enhanced Task-Solving in LLMs.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GISDMPR3","journalArticle","","Zhang, Daoan; Yao, Wenlin; Wang, Xiaoyang; Hu, Yebowen; Luo, Jiebo; Yu, Dong","MultiMedia-Agent: A Multimodal Agent for Multimedia Content Generation","","","","","https://openreview.net/forum?id=2JN73Z8f9Q","With the advancement of AIGC (AI-generated content) technologies, an increasing number of generative models are revolutionizing fields such as video editing, music generation, and even film production. However, due to the limitations of current AIGC models, most models can only serve as individual components within specific application scenarios and are not capable of completing tasks end-to-end in real-world applications. In real-world applications, editing experts often work with a wide variety of images and video inputs, producing multimodal outputs---a video typically includes audio, text, and other elements. This level of integration across multiple modalities is something current models are unable to achieve effectively. However, the rise of agent-based systems has made it possible to use AI tools to tackle complex content generation tasks. To deal with the complex scenarios, in this paper, we propose a multimedia content generation agent system designed to automate complex content creation. Our agent system includes a data generation pipeline, a tool library for content creation, and a set of metrics for evaluating preference alignment. Notably, we introduce the skill acquisition theory to model the training data curation and agent training. We designed a two-stage correlation strategy for plan optimization, including self-correlation and model preference correlation. Additionally, we utilized the generated plans to train the MultiMedia-Agent via a three stage approach including base/success plan finetune and preference optimization. The comparison results demonstrate that the our approaches are effective and the MultiMedia-Agent can generate better multimedia content compared to GPT4o.","","2025-05-22 20:04:59","2025-05-26 13:26:50","2025-05-22 20:04:57","","","","","","","MultiMedia-Agent","","","","","","","","","","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/EIG92PSP/Zhang et al. - MultiMedia-Agent A Multimodal Agent for Multimedia Content Generation.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DLNEKX58","journalArticle","2024","Graves, Russell Thomas","Controlling Complex Dynamic Transportation Systems: Development and Adaptation of a Novel Distributed Cooperative Multi-Agent Learning Technique","","","","","https://trace.tennessee.edu/utk_graddiss/10119/","Intelligent transportation systems continue to increase complexity, scale, and scope as more devices contain embedded compute. Cooperation among vehicles, intersections, and other members of the greater traffic ecosystem at a system-of-systems level is critical to improving the efficiency of the multi-billion-dollar asset that is the U.S. roadway infrastructure. This work introduces a negotiations strategy among multi-agent reinforcement learning agents and applies this to both traffic signal control and supervisory control of vehicle platooning. The traffic signal control implementation builds off of many prior research thrusts, and was shown to improve vehicle throughput by an average of 671veh/hr over actuated traffic under static arrival conditions. Additionally, the negotiations strategy saved 9.8sec and a maximum of 14.3sec in total travel time for a probe vehicle traversing the intersection system under static conditions. The realized efficiency increases resulted in an emissions reduction of 809kg/hr. In the case of platooning, the presented framework departs from the bulk of research, which tends to focus on the safety-critical and fine control of platooned vehicle motion; instead, this work chooses to approach platooning from a supervisory angle. Under the guidance of negotiated supervisory control, the maximum observed fuel savings was 20.8% in a low-traffic-density scenario over the nominal case where no vehicles are directed to platoon and closer to 7.2% when traffic is calibrated to match US highway 101. In each of these cases, the differences in mean speed between legacy driven vehicles and the vehicles supervised by the negotiations was < 5m/s. While the underlying representations for each of these systems is necessarily different. The results suggest that approaching the increasingly well-instrumented and controlled network of roadways with supervisory level controls yields an improvement in performance. The extension of this approach and future works are also addressed.","2024","2025-05-22 20:04:59","2025-05-26 13:22:46","2025-05-22 20:04:59","","","","","","","Controlling Complex Dynamic Transportation Systems","","","","","","","","","","","","Google Scholar","","","","/Users/ksoares/Zotero/storage/SIV9VAPN/Graves - 2024 - Controlling Complex Dynamic Transportation Systems Development and Adaptation of a Novel Distribute.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""