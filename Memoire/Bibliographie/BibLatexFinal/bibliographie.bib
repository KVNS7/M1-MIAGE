%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Définition de LLMs

@misc{cui_risk_2024,
	title = {Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems},
	doi = {10.48550/arXiv.2401.05778},
	abstract = {Large language models ({LLMs}) have strong capabilities in solving diverse natural language processing tasks. However, the safety and security issues of {LLM} systems have become the major obstacle to their widespread application. Many studies have extensively investigated risks in {LLM} systems and developed the corresponding mitigation strategies. Leading-edge enterprises such as {OpenAI}, Google, Meta, and Anthropic have also made lots of efforts on responsible {LLMs}. Therefore, there is a growing need to organize the existing studies and establish comprehensive taxonomies for the community. In this paper, we delve into four essential modules of an {LLM} system, including an input module for receiving prompts, a language model trained on extensive corpora, a toolchain module for development and deployment, and an output module for exporting {LLM}-generated content. Based on this, we propose a comprehensive taxonomy, which systematically analyzes potential risks associated with each module of an {LLM} system and discusses the corresponding mitigation strategies. Furthermore, we review prevalent benchmarks, aiming to facilitate the risk assessment of {LLM} systems. We hope that this paper can help {LLM} participants embrace a systematic perspective to build their responsible {LLM} systems.},
	number = {{arXiv}:2401.05778},
	publisher = {{arXiv}},
	author = {Cui, Tianyu and Wang, Yanling and Fu, Chuanpu and Xiao, Yong and Li, Sijia and Deng, Xinhao and Liu, Yunpeng and Zhang, Qinglin and Qiu, Ziyi and Li, Peiyang and Tan, Zhixing and Xiong, Junwu and Kong, Xinyu and Wen, Zujie and Xu, Ke and Li, Qi},
	date = {2024-01-11},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/ksoares/Zotero/storage/3RKJM9SC/Cui et al. - 2024 - Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems.pdf:application/pdf;Snapshot:/Users/ksoares/Zotero/storage/6RTF3GKF/2401.html:text/html},
}

@misc{wang_unique_2024,
	title = {Unique Security and Privacy Threats of Large Language Model: A Comprehensive Survey},
	doi = {10.48550/arXiv.2406.07973},
	shorttitle = {Unique Security and Privacy Threats of Large Language Model},
	abstract = {With the rapid development of artificial intelligence, large language models ({LLMs}) have made remarkable advancements in natural language processing. These models are trained on vast datasets to exhibit powerful language understanding and generation capabilities across various applications, including machine translation, chatbots, and agents. However, {LLMs} have revealed a variety of privacy and security issues throughout their life cycle, drawing significant academic and industrial attention. Moreover, the risks faced by {LLMs} differ significantly from those encountered by traditional language models. Given that current surveys lack a clear taxonomy of unique threat models across diverse scenarios, we emphasize the unique privacy and security threats associated with five specific scenarios: pre-training, fine-tuning, retrieval-augmented generation systems, deployment, and {LLM}-based agents. Addressing the characteristics of each risk, this survey outlines potential threats and countermeasures. Research on attack and defense situations can offer feasible research directions, enabling more areas to benefit from {LLMs}.},
	number = {{arXiv}:2406.07973},
	publisher = {{arXiv}},
	author = {Wang, Shang and Zhu, Tianqing and Liu, Bo and Ding, Ming and Guo, Xu and Ye, Dayong and Zhou, Wanlei and Yu, Philip S.},
	date = {2024-06-18},
	keywords = {Computer Science - Cryptography and Security},
	file = {Preprint PDF:/Users/ksoares/Zotero/storage/QDXS7M4N/Wang et al. - 2024 - Unique Security and Privacy Threats of Large Language Model A Comprehensive Survey.pdf:application/pdf;Snapshot:/Users/ksoares/Zotero/storage/RJDIK5SG/2406.html:text/html},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Définition d'Agents IA

@inproceedings{handler_taxonomy_2023,
	title = {A Taxonomy for Autonomous {LLM}-Powered Multi-Agent Architectures.},
	doi = {10.48550/arXiv.2310.03659},
	abstract = {Large language models ({LLMs}) have revolutionized the field of artificial intelligence, endowing it with sophisticated language understanding and generation capabilities. However, when faced with more complex and interconnected tasks that demand a profound and iterative thought process, {LLMs} reveal their inherent limitations. Autonomous {LLM}-powered multi-agent systems represent a strategic response to these challenges. While these architectures hold promising potential in amplifying {AI} capabilities, striking the right balance between different levels of autonomy and alignment remains the crucial challenge for their effective operation. This paper proposes a comprehensive multi-dimensional taxonomy, engineered to analyze how autonomous {LLM}-powered multi-agent systems balance the dynamic interplay between autonomy and alignment across various aspects inherent to architectural viewpoints such as goal-driven task management, agent composition, multi-agent collaboration, and context interaction. Our taxonomy aims to empower researchers, engineers, and {AI} practitioners to systematically analyze the architectural dynamics and balancing strategies employed by these increasingly prevalent {AI} systems. The exploratory taxonomic classification of selected representative {LLM}-powered multi-agent systems illustrates its practical utility and reveals potential for future research and development. An extended version of this paper is available on {arXiv} (Händler, 2023).},
	pages = {85--98},
	booktitle = {{KMIS}},
	author = {Händler, Thorsten},
	date = {2023},
	file = {Available Version (via Google Scholar):/Users/ksoares/Zotero/storage/IQPV887X/Händler - 2023 - A Taxonomy for Autonomous LLM-Powered Multi-Agent Architectures..pdf:application/pdf},
}

@article{handler_balancing_2023,
	title = {Balancing autonomy and alignment: a multi-dimensional taxonomy for autonomous {LLM}-powered multi-agent architectures},
	doi = {10.48550/arXiv.2310.03659},
	shorttitle = {Balancing autonomy and alignment},
	abstract = {Large language models ({LLMs}) have revolutionized the field of artificial intelligence, endowing it with sophisticated language understanding and generation capabilities. However, when faced with more complex and interconnected tasks that demand a profound and iterative thought process, {LLMs} reveal their inherent limitations. Autonomous {LLM}-powered multi-agent systems represent a strategic response to these challenges. Such systems strive for autonomously tackling user-prompted goals by decomposing them into manageable tasks and orchestrating their execution and result synthesis through a collective of specialized intelligent agents. Equipped with {LLM}-powered reasoning capabilities, these agents harness the cognitive synergy of collaborating with their peers, enhanced by leveraging contextual resources such as tools and datasets. While these architectures hold promising potential in amplifying {AI} capabilities, striking the right balance between different levels of autonomy and alignment remains the crucial challenge for their effective operation. This paper proposes a comprehensive multi-dimensional taxonomy, engineered to analyze how autonomous {LLM}-powered multi-agent systems balance the dynamic interplay between autonomy and alignment across various aspects inherent to architectural viewpoints such as goal-driven task management, agent composition, multi-agent collaboration, and context interaction. It also includes a domain-ontology model specifying fundamental architectural concepts. Our taxonomy aims to empower researchers, engineers, and {AI} practitioners to systematically analyze, compare, and understand the architectural dynamics and balancing strategies employed by these increasingly prevalent {AI} systems, thus contributing to ongoing efforts to develop more reliable and efficient solutions. The exploratory taxonomic classification of selected representative {LLM}-powered multi-agent systems illustrates its practical utility and reveals potential for future research and development.},
	journaltitle = {{arXiv} preprint {arXiv}:2310.03659},
	author = {Händler, Thorsten},
	date = {2023},
	file = {Available Version (via Google Scholar):/Users/ksoares/Zotero/storage/AWLBZSUT/Händler - 2023 - Balancing autonomy and alignment a multi-dimensional taxonomy for autonomous LLM-powered multi-agen.pdf:application/pdf},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Taille et composition d'équipe

@article{olivares_intelligent_2024,
	title = {Intelligent learning-based methods for determining the ideal team size in agile practices},
	volume = {9},
	doi = {10.3390/biomimetics9050292},
	abstract = {One of the significant challenges in scaling agile software development is organizing software development teams to ensure effective communication among members while equipping them with the capabilities to deliver business value independently. A formal approach to address this challenge involves modeling it as an optimization problem: given a professional staff, how can they be organized to optimize the number of communication channels, considering both intra-team and inter-team channels? In this article, we propose applying a set of bio-inspired algorithms to solve this problem. We introduce an enhancement that incorporates ensemble learning into the resolution process to achieve nearly optimal results. Ensemble learning integrates multiple machine-learning strategies with diverse characteristics to boost optimizer performance. Furthermore, the studied metaheuristics offer an excellent opportunity to explore their linear convergence, contingent on the exploration and exploitation phases. The results produce more precise definitions for team sizes, aligning with industry standards. Our approach demonstrates superior performance compared to the traditional versions of these algorithms.},
	pages = {292},
	number = {5},
	journaltitle = {Biomimetics},
	author = {Olivares, Rodrigo and Noel, Rene and Guzmán, Sebastián M. and Miranda, Diego and Munoz, Roberto},
	date = {2024},
	note = {Publisher: {MDPI}},
	file = {Available Version (via Google Scholar):/Users/ksoares/Zotero/storage/DL48DDHL/Olivares et al. - 2024 - Intelligent learning-based methods for determining the ideal team size in agile practices.pdf:application/pdf},
}

@article{bodaragama_exploring_2023,
	title = {Exploring the Impact of Team Size on Software Quality},
	doi = {10.22541/au.168431236.62929306/v1},
	abstract = {The relationship between team size and software quality has been a long-standing topic of debate in the software development industry. While larger teams were traditionally believed to be more productive and produce higher-quality software, recent research has shown that this relationship is more complex than originally thought. The paper examines several studies that have found conflicting results, highlighting the need for further research to explore the moderating factors that influence this relationship. The research suggests that team communication and coordination, developer experience, and project complexity are key factors that may interact with team size to influence software quality. Future studies should consider these moderating factors and use a range of quality metrics to provide a comprehensive assessment of software quality. These findings have important implications for project managers and software development teams who need to make informed decisions about team size and project planning. By optimizing team size and considering the factors that influence software quality, they can improve the overall quality of their software products. Effective communication and coordination among team members are critical to ensure that development efforts are aligned and productive, particularly when dealing with larger teams. Additionally, developers’ experience and the complexity of the project can affect the software quality outcome. Therefore, project managers must evaluate these factors and tailor team size and project planning accordingly to meet the desired quality objectives. Overall, the research provides insights into the complex relationship between team size and software quality, which can help project managers and software development teams make informed decisions to optimize their development efforts. By leveraging the moderating factors that influence software quality, teams can better understand how to improve their software products’ overall quality, leading to better outcomes for their organizations and end-users.},
	journaltitle = {Authorea Preprints},
	author = {Bodaragama, B. D. T. and Vipulasiri, {DMHD} and {DI}, De Silva and {JayakodY}, {TWSL}},
	date = {2023},
	note = {Publisher: Authorea},
	file = {Available Version (via Google Scholar):/Users/ksoares/Zotero/storage/LKULA3W6/Bodaragama et al. - 2023 - Exploring the Impact of Team Size on Software Quality.pdf:application/pdf},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Automatisation du développement par Agents IA

@article{ashraf_autonomous_2025,
	title = {Autonomous Agents in Software Engineering: A Multi-Agent {LLM} Approach},
	doi = {10.13140/RG.2.2.22360.61448},
	shorttitle = {Autonomous Agents in Software Engineering},
	abstract = {The integration of autonomous agents in software engineering has the potential to revolutionize
traditional development processes by automating complex tasks, enhancing collaboration, and
optimizing productivity. Large Language Models ({LLMs}) have emerged as powerful tools for
facilitating autonomous agent interactions, enabling software engineering workflows to be more
intelligent and adaptive. This paper explores a multi-agent {LLM} approach, where autonomous
agents perform various roles such as requirement analysis, code generation, testing, and
debugging. By leveraging natural language processing capabilities, these agents can communicate,
make decisions, and execute tasks with minimal human intervention. Experimental results
demonstrate that multi-agent {LLMs} can streamline software development, reduce human errors,
and accelerate project timelines. However, challenges related to model interpretability,
coordination complexities, and error handling remain critical concerns. This study discusses the
benefits, limitations, and future implications of integrating multi-agent {LLMs} in software
engineering, emphasizing the need for further research to enhance agent reliability, contextual
awareness, and ethical considerations. The findings suggest that a well-structured autonomous
agent system can significantly improve software engineering efficiency while complementing
human expertise in an agile development environment.},
	author = {Ashraf, Bilal and Talavera, Gregory},
	date = {2025},
	file = {PDF:/Users/ksoares/Zotero/storage/R835DEB3/Ashraf et Talavera - 2025 - Autonomous Agents in Software Engineering A Multi-Agent LLM Approach.pdf:application/pdf},
}

@article{khan_ai-driven_2025,
	title = {{AI}-Driven Automation in Agile Development: Multi-Agent {LLMs} for Software Engineering},
	doi = {10.13140/RG.2.2.20682.89281},
	shorttitle = {{AI}-Driven Automation in Agile Development},
	abstract = {The integration of {AI}-driven automation in agile software development has gained significant
momentum, with large language models ({LLMs}) playing a crucial role in streamlining workflows.
This study explores the potential of multi-agent {LLM} systems in enhancing various aspects of
software engineering, including code generation, bug detection, documentation, and project
management. By leveraging multiple specialized {AI} agents that collaborate dynamically, we
analyze how automation can improve development efficiency while maintaining code quality and
adaptability. Our research implements and evaluates a multi-agent framework, assessing its impact
on sprint planning, automated testing, and continuous integration pipelines. Experimental results
demonstrate that multi-agent {LLMs} can effectively reduce development time, enhance team
productivity, and provide real-time decision support, making them valuable assets in agile
environments. However, challenges such as model interpretability, error propagation, and
alignment with human developers remain critical concerns. This study highlights the benefits and
limitations of {AI}-driven automation in agile development and suggests future directions for
optimizing multi-agent {LLM} frameworks for software engineering.},
	author = {Khan, Salman and Daviglus, Mendus},
	date = {2025},
	file = {PDF:/Users/ksoares/Zotero/storage/IECXHFTE/Khan et Daviglus - 2025 - AI-Driven Automation in Agile Development Multi-Agent LLMs for Software Engineering.pdf:application/pdf},
}

@article{zahid_multi-agent_2024,
	title = {Multi-Agent {AI} Collaboration: Advancing Software Engineering with Autonomous {LLMs}},
	doi = {10.13140/RG.2.2.18585.74080},
	shorttitle = {Multi-Agent {AI} Collaboration},
	abstract = {The integration of multi-agent {AI} systems into software engineering is transforming traditional
development workflows. Large Language Models ({LLMs}), when used collaboratively, enhance
automation, streamline coding processes, and improve overall software quality. This paper
explores the role of autonomous {LLMs} in multi-agent {AI} collaboration, focusing on their impact
on code generation, debugging, project management, and software lifecycle optimization. Multiagent {AI} collaboration leverages distributed problem-solving, where multiple {LLMs} specialize in
different aspects of software development. By automating repetitive tasks, such as writing
boilerplate code and generating documentation, these {AI} agents reduce developer workload and
enhance productivity. Additionally, they assist in identifying code inefficiencies, detecting security
vulnerabilities, and refining algorithms with minimal human intervention. One of the key
challenges in {AI}-driven software engineering is ensuring seamless communication and
coordination among multiple agents. This paper examines techniques for optimizing multi-agent
interactions, including reinforcement learning, agent-based task delegation, and contextual
awareness. The research also highlights the ethical and practical considerations of {AI} in software
engineering. While multi-agent {LLMs} offer significant advantages, challenges such as {AI} bias,
hallucinations, and reliability must be addressed to ensure responsible {AI} adoption. By integrating
explainability frameworks and human oversight mechanisms, organizations can leverage {AI}
collaboration while maintaining accountability and transparency. This study concludes that multiagent {AI} systems are poised to revolutionize software engineering by enhancing automation,
reducing development time, and improving software robustness.},
	author = {Zahid, Ismail and Hussain, Ijaz},
	date = {2024},
	file = {PDF:/Users/ksoares/Zotero/storage/JB55JXCD/Zahid et Hussain - 2024 - Multi-Agent AI Collaboration Advancing Software Engineering with Autonomous LLMs.pdf:application/pdf},
}

@inproceedings{vallecillos_ruiz_agent-driven_2024,
	location = {Salerno Italy},
	title = {Agent-Driven Automatic Software Improvement},
	isbn = {979-8-4007-1701-7},
	doi = {10.1145/3661167.3661171},
	abstract = {With software maintenance accounting for 50\% of the cost of developing software, enhancing code quality and reliability has become more critical than ever. In response to this challenge, this doctoral research proposal aims to explore innovative solutions by focusing on the deployment of agents powered by Large Language Models ({LLMs}) to perform software maintenance tasks. The iterative nature of agents, which allows for continuous learning and adaptation, can help surpass common challenges in code generation. One distinct challenge is the last-mile problems, errors at the final stage of producing functionally and contextually relevant code. Furthermore, this project aims to surpass the inherent limitations of current {LLMs} in source code through a collaborative framework where agents can correct and learn from each other’s errors. We aim to use the iterative feedback in these systems to further fine-tune the {LLMs} underlying the agents, becoming better aligned to the task of automated software improvement. Our main goal is to achieve a leap forward in the field of automatic software improvement by developing new tools and frameworks that can enhance the efficiency and reliability of software development.},
	eventtitle = {{EASE} 2024: 28th International Conference on Evaluation and Assessment in Software Engineering},
	pages = {470--475},
	booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
	publisher = {{ACM}},
	author = {Vallecillos Ruiz, Fernando},
	date = {2024-06-18},
	langid = {english},
	file = {Available Version (via Google Scholar):/Users/ksoares/Zotero/storage/HG84XDYZ/Vallecillos Ruiz - 2024 - Agent-Driven Automatic Software Improvement.pdf:application/pdf},
}

@article{abbas_ai-driven_2024,
	title = {{AI}-Driven Agile Development: How Multi-Agent {LLMs} Optimize Engineering Workflows},
	doi = {10.13140/RG.2.2.23618.90566},
	shorttitle = {{AI}-Driven Agile Development},
	abstract = {{AI}-driven Agile development is transforming engineering workflows by integrating multi-agent
Large Language Models ({LLMs}) to enhance collaboration, automation, and decision-making.
Traditional Agile methodologies rely on iterative development, rapid feedback, and continuous
improvement, but {AI}-powered multi-agent systems optimize these processes by automating
repetitive tasks, analyzing vast datasets, and providing intelligent recommendations. Multi-agent
{LLMs} function as autonomous entities capable of handling various aspects of software
development, including code generation, bug detection, requirement analysis, and project
management. By leveraging these {AI}-driven agents, teams can accelerate development cycles,
reduce human errors, and improve overall software quality. These models also facilitate real-time
collaboration by processing vast amounts of information, summarizing key insights, and
optimizing sprint planning. One of the critical advantages of {AI}-driven Agile development is
enhanced efficiency. Automated backlog prioritization, intelligent risk assessment, and real-time
code reviews allow engineering teams to focus on innovation rather than manual administrative
tasks. Multi-agent systems improve workflow coordination by distributing workloads dynamically
based on project demands and developer expertise, ensuring optimal resource allocation. Despite
these benefits, integrating {AI}-driven multi-agent {LLMs} into Agile development presents
challenges, including ethical considerations, data security risks, and maintaining human oversight.
Ensuring transparency, interpretability, and ethical {AI} usage is essential for successful
implementation. Moreover, {AI} models require continuous updates to adapt to evolving
development needs and maintain accuracy in recommendations.},
	author = {Abbas, Ghulam and Wahab, Abdul},
	date = {2024},
	file = {PDF:/Users/ksoares/Zotero/storage/KNNLS9GN/Abbas et Wahab - 2024 - AI-Driven Agile Development How Multi-Agent LLMs Optimize Engineering Workflows.pdf:application/pdf},
}

@misc{rasheed_codepori_2024,
	title = {{CodePori}: Large-Scale System for Autonomous Software Development Using Multi-Agent Technology},
	doi = {10.48550/arXiv.2402.01411},
	shorttitle = {{CodePori}},
	abstract = {Context: Large Language Models ({LLMs}) and Generative Pre-trained Transformers ({GPTs}) have transformed the field of Software Engineering ({SE}). Existing {LLM}-based multi-agent models have successfully addressed basic dialogue tasks. However, the potential of {LLMs} for more challenging tasks, such as automated code generation for large and complex projects, has been investigated in only a few existing works. Objective: This paper aims to investigate the potential of {LLM}-based agents in the software industry, particularly in enhancing productivity and reducing time-to-market for complex software solutions. Our primary objective is to gain insights into how these agents can fundamentally transform the development of large-scale software. Methods: We introduce {CodePori}, a novel system designed to automate code generation for large and complex software projects based on functional and non-functional requirements defined by stakeholders. To assess the proposed system performance, we utilized the {HumanEval} benchmark and manually tested the {CodePori} model, providing 20 different project descriptions as input and then evaluated the code accuracy by manually executing the code. Results: {CodePori} is able to generate running code for large-scale projects, aligned with the typical software development process. The {HumanEval} benchmark results indicate that {CodePori} improves code accuracy by 89\%. A manual assessment conducted by the first author shows that the {CodePori} system achieved an accuracy rate of 85\%. Conclusion: Based on the results, our conclusion is that proposed system demonstrates the transformative potential of {LLM}-based agents in {SE}, highlighting their practical applications and opening new opportunities for broader adoption in both industry and academia. Our project is publicly available at https://github.com/{GPT}-Laboratory/{CodePori}.},
	number = {{arXiv}:2402.01411},
	publisher = {{arXiv}},
	author = {Rasheed, Zeeshan and Sami, Malik Abdul and Kemell, Kai-Kristian and Waseem, Muhammad and Saari, Mika and Systä, Kari and Abrahamsson, Pekka},
	date = {2024-09-17},
	keywords = {Computer Science - Software Engineering},
	file = {Preprint PDF:/Users/ksoares/Zotero/storage/W4WK242D/Rasheed et al. - 2024 - CodePori Large-Scale System for Autonomous Software Development Using Multi-Agent Technology.pdf:application/pdf;Snapshot:/Users/ksoares/Zotero/storage/PKLS5372/2402.html:text/html},
}
