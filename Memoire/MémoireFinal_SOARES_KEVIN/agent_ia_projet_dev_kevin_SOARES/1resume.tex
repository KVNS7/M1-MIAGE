\chapter*{Résumés ($1$ page)}
\section*{Résumé}
Les progrès récents des Large Language Models (LLMs) et des architectures multi-agents soulèvent une question audacieuse : peut-on remplacer une équipe de développement logicielle par un collectif d’agents IA ?  Afin d’éclairer ce débat, ce mémoire dresse d’abord l’état de l’art des LLMs appliqués au génie logiciel, puis cartographie les fonctions clés, de l’analyse d’exigences à la mise en production, qu’une équipe doit assumer.  L’examen de trois prototypes représentatifs (\textit{CodePori}, \textit{Agent-Driven Automatic Software Improvement} et un pipeline Auto-DevOps multi-agents) montre que la génération, les tests et le débogage peuvent déjà être automatisés avec un taux de précision compris entre 80 et 90\%.  Cependant, les risques de biais, d’hallucinations et de fuites de données obligent à maintenir des garde-fous et une supervision humaine, notamment pour l’architecture et la gouvernance.  Une matrice SWOT met en évidence des forces (exécution 24 / 7, coûts réduits), mais aussi des menaces (responsabilité légale, attaques backdoor).  Trois scénarios d’évolution sont proposés : \emph{développement assisté} à court terme, \emph{équipes hybrides} à moyen terme, puis \emph{autonomie quasi complète} sous audits périodiques.  La conclusion affirme que le remplacement total est techniquement concevable, mais conditionné à l’alignement, à la sécurité et à un cadre réglementaire robuste.  Ce travail offre ainsi un outil d’aide à la décision pour chercheurs, industriels et législateurs confrontés à l’émergence des équipes 100\% IA.

\section*{Abstract}
Recent advances in \emph{Large Language Models} (LLMs) and multi-agent systems raise a bold question: can a software development team be entirely replaced by AI agents?  To address this, the thesis first surveys state-of-the-art LLM techniques for software engineering and maps essential roles, from requirements analysis to production deployment, that any team must cover.  Three representative prototypes (\textit{CodePori}, \textit{Agent-Driven Automatic Software Improvement}, and an Auto-DevOps multi-agent pipeline) reveal that code generation, testing and debugging can already be automated with 80 to 90\% accuracy.  Yet bias, hallucinations and data-leak risks still demand human oversight for architecture and governance.  A SWOT matrix highlights strengths (24 / 7 execution, lower recurring costs) and threats (legal accountability, backdoor attacks).  Building on this analysis, three evolution scenarios are outlined: \emph{AI-assisted pair programming} in the short term, \emph{lean hybrid teams} mid-term, and near-full autonomy under periodic audits in the long run.  The thesis concludes that full replacement is technically plausible but contingent upon reliable alignment, strong security guarantees and a clear regulatory framework.  Overall, the work provides a decision-making tool for researchers, practitioners and policymakers facing the rise of “all-AI” development teams.
