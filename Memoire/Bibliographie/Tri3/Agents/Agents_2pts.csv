Key,Item Type,Publication Year,Author,Title,Publication Title,ISBN,ISSN,DOI,Url,Abstract Note,Date,Date Added,Date Modified,Access Date,Pages,Num Pages,Issue,Volume,Number Of Volumes,Journal Abbreviation,Short Title,Series,Series Number,Series Text,Series Title,Publisher,Place,Language,Rights,Type,Archive,Archive Location,Library Catalog,Call Number,Extra,Notes,File Attachments,Link Attachments,Manual Tags,Automatic Tags,Editor,Series Editor,Translator,Contributor,Attorney Agent,Book Author,Cast Member,Commenter,Composer,Cosponsor,Counsel,Interviewer,Producer,Recipient,Reviewed Author,Scriptwriter,Words By,Guest,Number,Edition,Running Time,Scale,Medium,Artwork Size,Filing Date,Application Number,Assignee,Issuing Authority,Country,Meeting Name,Conference Name,Court,References,Reporter,Legal Status,Priority Numbers,Programming Language,Version,System,Code,Code Number,Section,Session,Committee,History,Legislative Body,Score
D3XICYMG,journalArticle,2024.0,"Wachowiak, Lennart; Coles, Andrew; Canal, Gerard; Celiktutan, Oya",A Taxonomy of Explanation Types and Need Indicators in Human–Agent Collaborations,International Journal of Social Robotics,,"1875-4791, 1875-4805",10.1007/s12369-024-01148-8,https://link.springer.com/10.1007/s12369-024-01148-8,"Abstract             In recent years, explanations have become a pressing matter in AI research. This development was caused by the increased use of black-box models and a realization of the importance of trustworthy AI. In particular, explanations are necessary for human–agent interactions to ensure that the user can trust the agent and that collaborations are effective. Human–agent interactions are complex social scenarios involving a user, an autonomous agent, and an environment or task with its own distinct properties. Thus, such interactions require a wide variety of explanations, which are not covered by the methods of a single AI discipline, such as computer vision or natural language processing. In this paper, we map out what types of explanations are important for human–agent interactions, surveying the field via a scoping review. In addition to the typical introspective explanation tackled by explainability researchers, we look at assistive explanations, aiming to support the user with their task. Secondly, we survey what causes the need for an explanation in the first place. We identify a variety of human–agent interaction-specific causes and categorize them by whether they are centered on the agent’s behavior, the user’s mental state, or an external entity. Our overview aims to guide robotics practitioners in designing agents with more comprehensive explanation-related capacities, considering different explanation types and the concrete times when explanations should be given.",2024-07,2025-05-22 17:48:44,2025-05-22 17:48:44,2025-05-22 17:48:36,1681-1692,,7,16.0,,Int J of Soc Robotics,,,,,,,,en,,,,,DOI.org (Crossref),,,,/Users/ksoares/Zotero/storage/8Y7GUELW/Wachowiak et al. - 2024 - A Taxonomy of Explanation Types and Need Indicators in Human–Agent Collaborations.pdf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2
GSVB52SU,conferencePaper,2022.0,"Brandao, Martim; Mansouri, Masoumeh; Mohammed, Areeb; Luff, Paul; Coles, Amanda",Explainability in multi-agent path/motion planning: User-study-driven taxonomy and requirements,International Conference on Autonomous Agents and Multiagent Systems (AAMAS),,,,https://kclpure.kcl.ac.uk/portal/en/publications/explainability-in-multi-agent-pathmotion-planning-user-study-driv,"Multi-Agent Path Finding (MAPF) and Multi-Robot Motion Planning (MRMP) are complex problems to solve, analyze and build algorithms for. Automatically-generated explanations of algorithm output, by improving human understanding of the underlying problems and algorithms, could thus lead to better user experience, developer knowledge, and MAPF/MRMP algorithm designs. Explanations are contextual, however, and thus developers need a good understanding of the questions that can be asked about algorithm output, the kinds of explanations that exist, and the potential users and uses of explanations in MAPF/MRMP applications. In this paper we provide a first step towards establishing a taxonomy of explanations, and a list of requirements for the development of explainable MAPF/MRMP planners. We use interviews and a questionnaire with expert developers and industry practitioners to identify the kinds of questions, explanations, users, uses, and requirements of explanations that should be considered in the design of such explainable planners. Our insights cover a diverse set of applications: warehouse automation, computer games, and mining.",2022,2025-05-22 17:48:44,2025-05-26 12:40:57,2025-05-22 17:48:44,,,,,,,Explainability in multi-agent path/motion planning,,,,,,,,,,,,Google Scholar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2
I3KK5WQZ,bookSection,2021.0,"Johnson, Craig J.; Lematta, Glenn J.; Huang, Lixiao; Holder, Eric; Bhatti, Shawaiz; Cooke, Nancy J.",An Interaction Taxonomy of Human–Agent Teaming in Next Generation Combat Vehicle Systems,"Advances in Human Factors in Robots, Drones and Unmanned Systems",978-3-030-51757-1 978-3-030-51758-8,,,http://link.springer.com/10.1007/978-3-030-51758-8_2,"Next Generation Combat Vehicles (NGCVs) are incorporating more advanced technology which will enable humans and intelligent artificial agents to team up on the battlefield. Effective system design and evaluation for these human–agent teams require an understanding of individual and team tasks in the context of larger-scale operations. Previous taxonomies of human–automation interaction and human–agent teaming have been proposed, however, there is a lack of work focused on team interactions in the military domain and the teamwork dynamics required for our purposes are not captured. Unstructured interviews with subject matter experts, manuals, and relevant literature were synthesized, and a task analysis was conducted to develop a novel interaction taxonomy approach consisting of three primary categories, each with multiple dimensions: task, team composition, and communication. This taxonomy may generalize into human–agent teaming within a variety of NGCV crews and serve as a model for characterizing human–agent team interactions in other domains.",2021,2025-05-22 17:50:28,2025-05-26 12:39:56,2025-05-22 17:50:14,10-16,,,1210.0,,,,,,,,Springer International Publishing,Cham,en,,,,,DOI.org (Crossref),,Series Title: Advances in Intelligent Systems and Computing DOI: 10.1007/978-3-030-51758-8_2,,,,,,"Zallio, Matteo",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2
