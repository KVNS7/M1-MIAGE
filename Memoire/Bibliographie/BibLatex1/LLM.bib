
@misc{cui_risk_2024,
	title = {Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems},
	url = {http://arxiv.org/abs/2401.05778},
	doi = {10.48550/arXiv.2401.05778},
	abstract = {Large language models ({LLMs}) have strong capabilities in solving diverse natural language processing tasks. However, the safety and security issues of {LLM} systems have become the major obstacle to their widespread application. Many studies have extensively investigated risks in {LLM} systems and developed the corresponding mitigation strategies. Leading-edge enterprises such as {OpenAI}, Google, Meta, and Anthropic have also made lots of efforts on responsible {LLMs}. Therefore, there is a growing need to organize the existing studies and establish comprehensive taxonomies for the community. In this paper, we delve into four essential modules of an {LLM} system, including an input module for receiving prompts, a language model trained on extensive corpora, a toolchain module for development and deployment, and an output module for exporting {LLM}-generated content. Based on this, we propose a comprehensive taxonomy, which systematically analyzes potential risks associated with each module of an {LLM} system and discusses the corresponding mitigation strategies. Furthermore, we review prevalent benchmarks, aiming to facilitate the risk assessment of {LLM} systems. We hope that this paper can help {LLM} participants embrace a systematic perspective to build their responsible {LLM} systems.},
	number = {{arXiv}:2401.05778},
	publisher = {{arXiv}},
	author = {Cui, Tianyu and Wang, Yanling and Fu, Chuanpu and Xiao, Yong and Li, Sijia and Deng, Xinhao and Liu, Yunpeng and Zhang, Qinglin and Qiu, Ziyi and Li, Peiyang and Tan, Zhixing and Xiong, Junwu and Kong, Xinyu and Wen, Zujie and Xu, Ke and Li, Qi},
	urldate = {2025-05-22},
	date = {2024-01-11},
	eprinttype = {arxiv},
	eprint = {2401.05778 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:/Users/ksoares/Zotero/storage/3RKJM9SC/Cui et al. - 2024 - Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems.pdf:application/pdf;Snapshot:/Users/ksoares/Zotero/storage/6RTF3GKF/2401.html:text/html},
}

@misc{wang_unique_2024,
	title = {Unique Security and Privacy Threats of Large Language Model: A Comprehensive Survey},
	url = {http://arxiv.org/abs/2406.07973},
	doi = {10.48550/arXiv.2406.07973},
	shorttitle = {Unique Security and Privacy Threats of Large Language Model},
	abstract = {With the rapid development of artificial intelligence, large language models ({LLMs}) have made remarkable advancements in natural language processing. These models are trained on vast datasets to exhibit powerful language understanding and generation capabilities across various applications, including machine translation, chatbots, and agents. However, {LLMs} have revealed a variety of privacy and security issues throughout their life cycle, drawing significant academic and industrial attention. Moreover, the risks faced by {LLMs} differ significantly from those encountered by traditional language models. Given that current surveys lack a clear taxonomy of unique threat models across diverse scenarios, we emphasize the unique privacy and security threats associated with five specific scenarios: pre-training, fine-tuning, retrieval-augmented generation systems, deployment, and {LLM}-based agents. Addressing the characteristics of each risk, this survey outlines potential threats and countermeasures. Research on attack and defense situations can offer feasible research directions, enabling more areas to benefit from {LLMs}.},
	number = {{arXiv}:2406.07973},
	publisher = {{arXiv}},
	author = {Wang, Shang and Zhu, Tianqing and Liu, Bo and Ding, Ming and Guo, Xu and Ye, Dayong and Zhou, Wanlei and Yu, Philip S.},
	urldate = {2025-05-22},
	date = {2024-06-18},
	eprinttype = {arxiv},
	eprint = {2406.07973 [cs]},
	keywords = {Computer Science - Cryptography and Security},
	file = {Preprint PDF:/Users/ksoares/Zotero/storage/QDXS7M4N/Wang et al. - 2024 - Unique Security and Privacy Threats of Large Language Model A Comprehensive Survey.pdf:application/pdf;Snapshot:/Users/ksoares/Zotero/storage/RJDIK5SG/2406.html:text/html},
}
